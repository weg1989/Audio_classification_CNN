{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935567c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "[2023-08-03 23:25:20,773] ERROR in app: Exception on /predict [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jay\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\flask\\app.py\", line 2190, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\Jay\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\flask\\app.py\", line 1486, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\Jay\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\flask\\app.py\", line 1484, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\Jay\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\flask\\app.py\", line 1469, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "  File \"C:\\Users\\Jay\\AppData\\Local\\Temp\\ipykernel_19900\\374599200.py\", line 111, in predict\n",
      "    prediction = cnn(signal1)\n",
      "  File \"C:\\Users\\Jay\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"E:\\DL_audio\\with_pytorch\\cnn.py\", line 75, in forward\n",
      "    return self.softmax(self.linear(self.flatten(x)))\n",
      "  File \"C:\\Users\\Jay\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\Jay\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (128x20 and 2560x10)\n",
      "127.0.0.1 - - [03/Aug/2023 23:25:20] \"POST /predict HTTP/1.1\" 500 -\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset\n",
    "from cnn import CNNNetwork\n",
    "import numpy as np\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "import pickle\n",
    "class_mapping = [\n",
    "    \"air_conditioner\",\n",
    "    \"car_horn\",\n",
    "    \"children_playing\",\n",
    "    \"dog_bark\",\n",
    "    \"drilling\",\n",
    "    \"engine_idling\",\n",
    "    \"gun_shot\",\n",
    "    \"jackhammer\",\n",
    "    \"siren\",\n",
    "    \"street_music\"\n",
    "]\n",
    "\n",
    "class UrbanSoundDataset_load_to_predict(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 audio_sample_path,\n",
    "                 transformation,\n",
    "                 target_sample_rate,\n",
    "                 num_samples):\n",
    "        self.audio_sample_path = audio_sample_path\n",
    "        self.transformation = transformation\n",
    "        self.target_sample_rate = target_sample_rate\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "\n",
    "    def __getitem__(self, audio_sample_path):\n",
    "        signal, sr = torchaudio.load(audio_sample_path)\n",
    "        signal = self._resample_if_necessary(signal, sr)\n",
    "        signal = self._mix_down_if_necessary(signal)\n",
    "        signal = self._cut_if_necessary(signal)\n",
    "        signal = self._right_pad_if_necessary(signal)\n",
    "        signal = self.transformation(signal)\n",
    "        return signal\n",
    "\n",
    "    def _cut_if_necessary(self, signal):\n",
    "        if signal.shape[1] > self.num_samples:\n",
    "            signal = signal[:, :self.num_samples]\n",
    "        return signal\n",
    "\n",
    "    def _right_pad_if_necessary(self, signal):\n",
    "        length_signal = signal.shape[1]\n",
    "        if length_signal < self.num_samples:\n",
    "            num_missing_samples = self.num_samples - length_signal\n",
    "            last_dim_padding = (0, num_missing_samples)\n",
    "            signal = torch.nn.functional.pad(signal, last_dim_padding)\n",
    "        return signal\n",
    "\n",
    "    def _resample_if_necessary(self, signal, sr):\n",
    "        if sr != self.target_sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate)\n",
    "            signal = resampler(signal)\n",
    "        return signal\n",
    "\n",
    "    def _mix_down_if_necessary(self, signal):\n",
    "        if signal.shape[0] > 1:\n",
    "            signal = torch.mean(signal, dim=0, keepdim=True)\n",
    "        return signal\n",
    "\n",
    "#     def _get_audio_sample_path(self, index):\n",
    "#         fold = f\"fold{self.annotations.iloc[index, 5]}\"\n",
    "#         path = os.path.join(self.audio_dir, fold, self.annotations.iloc[\n",
    "#             index, 0])\n",
    "#         return path\n",
    "\n",
    "    def _get_audio_sample_label(self, index):\n",
    "        return self.annotations.iloc[index, 6]\n",
    "    \n",
    "def predict(model, input, class_mapping):\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        predictions = model(input)\n",
    "        # Tensor (1, 10) -> [ [0.1, 0.01, ..., 0.6] ]\n",
    "        predicted_index = predictions[0].argmax(0)\n",
    "        predicted = class_mapping[predicted_index]\n",
    "        expected = class_mapping[target]\n",
    "    return predicted, expected\n",
    "\n",
    "cnn = CNNNetwork()\n",
    "state_dict = torch.load(\"cnnnet.pth\")\n",
    "cnn.load_state_dict(state_dict)\n",
    "    \n",
    "SAMPLE_RATE=16000\n",
    "NUM_SAMPLES = 22050\n",
    "\n",
    "mel_spec = torchaudio.transforms.MelSpectrogram(sample_rate = SAMPLE_RATE,\n",
    "                                              n_fft = 1024,\n",
    "                                              hop_length = 512,\n",
    "                                              n_mels = 64)\n",
    "\n",
    "\n",
    "\n",
    "flask_app = Flask(__name__)\n",
    "\n",
    "@flask_app.route(\"/\")\n",
    "def Home():\n",
    "    return \"Hii\"\n",
    "\n",
    "@flask_app.route(\"/predict\", methods = [\"POST\"])\n",
    "def predict():\n",
    "    audio_sample_path=request.files['audio']\n",
    "    signal = UrbanSoundDataset_load_to_predict(r\"E:\\DL_audio\\with_pytorch\\UrbanSound8K\\audio\\fold1\\7061-6-0-0.wav\",mel_spec,SAMPLE_RATE,NUM_SAMPLES)\n",
    "    signal1 = signal.__getitem__(r\"E:\\DL_audio\\with_pytorch\\UrbanSound8K\\audio\\fold1\\7061-6-0-0.wav\")\n",
    "    prediction = cnn(signal1)\n",
    "    predicted_index = predictions[0].argmax(0)\n",
    "    prediction = class_mapping[predicted_index]\n",
    "    return render_template(\"index.html\", prediction_text = \"The flower species is {}\".format(prediction))\n",
    "\n",
    "\n",
    "flask_app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417c237d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
