{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "134cc523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from load_data_gpu import UrbanSoundDataset\n",
    "import torchaudio\n",
    "from cnn import CNNNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bcb8385b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Steup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9658135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(train_data, batch_size):\n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "    return train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "858702c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.7433e-03, 1.6207e-04, 4.0781e-04,  ..., 2.0526e-03,\n",
      "          6.8678e-03, 1.7846e-02],\n",
      "         [6.4027e-04, 5.4754e-03, 2.8272e-02,  ..., 5.5625e-03,\n",
      "          8.6759e-02, 5.2350e-02],\n",
      "         [1.0592e-03, 1.2941e-02, 8.1117e-02,  ..., 5.6558e-03,\n",
      "          6.1651e-02, 1.0182e-01],\n",
      "         ...,\n",
      "         [4.8316e-06, 2.0553e-06, 2.5774e-06,  ..., 3.5377e-06,\n",
      "          3.0520e-06, 4.1328e-06],\n",
      "         [4.0104e-06, 4.2231e-06, 4.8558e-06,  ..., 1.7981e-06,\n",
      "          3.2201e-06, 6.0627e-06],\n",
      "         [4.0844e-06, 4.0532e-06, 4.6760e-06,  ..., 1.6818e-06,\n",
      "          3.3693e-06, 2.2788e-06]]], device='cuda:0')\n",
      "3\n",
      "torch.Size([1, 64, 44])\n",
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANNOTATIONS_FILE = r\"E:\\DL_audio\\with_pytorch\\data1\\metadata\\fold_1_annotation.csv\"\n",
    "AUDIO_DIR = r\"E:\\DL_audio\\with_pytorch\\data1\\audio\"\n",
    "\n",
    "SAMPLE_RATE=22050\n",
    "NUM_SAMPLES = 22050\n",
    "\n",
    "mel_spec = torchaudio.transforms.MelSpectrogram(sample_rate = SAMPLE_RATE,\n",
    "                                              n_fft = 1024,\n",
    "                                              hop_length = 512,\n",
    "                                              n_mels = 64)\n",
    "    \n",
    "usd = UrbanSoundDataset(ANNOTATIONS_FILE,AUDIO_DIR,mel_spec,SAMPLE_RATE,NUM_SAMPLES,device)\n",
    "\n",
    "signal , label = usd[0]\n",
    "\n",
    "print(signal) , print(label) , print(signal.shape), print(signal.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fd4d32",
   "metadata": {},
   "source": [
    "train = 0.8*len(usd)\n",
    "\n",
    "train_data = usd[:train]\n",
    "test_data = usd[train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4dce42ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataloader\n",
    "Batch=128\n",
    "\n",
    "train_data_loader = create_data_loader(usd, batch_size=Batch)\n",
    "#test_data_loader = create_data_loader(test_data, batch_size=Batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9965efde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNNetwork(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear): Linear(in_features=2560, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_0 = CNNNetwork().to(device)\n",
    "print(model_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d8aa7874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true,y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred))*100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9442fe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, data_loader, loss_fn, accuracy_fn, optimizer, device):\n",
    "    \n",
    "    model.train()\n",
    "    for X,y in data_loader:\n",
    "        X , y = X.to(device) , y.to(device)\n",
    "        \n",
    "        y_logits = model(X).squeeze()\n",
    "        y_preds = torch.argmax(torch.round(torch.sigmoid(y_logits)),dim=1)\n",
    "        \n",
    "        #print(y_preds) , print(y)\n",
    "        \n",
    "        loss = loss_fn(y_logits,y)\n",
    "        acc = accuracy_fn(y,y_preds)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f\"Loss: {loss}| Acc: {acc}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c949db",
   "metadata": {},
   "source": [
    "def test_step(model, data_loader, loss_fn, device):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        \n",
    "        for X,y in data_loader:\n",
    "            X , y = X.to(device) , y.to(device)\n",
    "\n",
    "            test_pred = model(X)\n",
    "\n",
    "            test_loss = loss_fn(test_pred,y)\n",
    "\n",
    "        \n",
    "    print(f\"Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cf67c1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
    "                            lr=LEARNING_RATE,\n",
    "                           weight_decay=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8a363c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cbdecb1696844cfbecd03b0770e0442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \n",
      "-----------\n",
      "Loss: 2.3567733764648438| Acc: 2.857142857142857\n",
      "Epoch: 1 \n",
      "-----------\n",
      "Loss: 2.2933666706085205| Acc: 2.857142857142857\n",
      "Epoch: 2 \n",
      "-----------\n",
      "Loss: 2.2402215003967285| Acc: 8.571428571428571\n",
      "Epoch: 3 \n",
      "-----------\n",
      "Loss: 2.2324366569519043| Acc: 8.571428571428571\n",
      "Epoch: 4 \n",
      "-----------\n",
      "Loss: 2.229637861251831| Acc: 9.523809523809524\n",
      "Epoch: 5 \n",
      "-----------\n",
      "Loss: 2.2306830883026123| Acc: 9.523809523809524\n",
      "Epoch: 6 \n",
      "-----------\n",
      "Loss: 2.2279741764068604| Acc: 10.476190476190476\n",
      "Epoch: 7 \n",
      "-----------\n",
      "Loss: 2.2274060249328613| Acc: 11.428571428571429\n",
      "Epoch: 8 \n",
      "-----------\n",
      "Loss: 2.2267279624938965| Acc: 11.428571428571429\n",
      "Epoch: 9 \n",
      "-----------\n",
      "Loss: 2.224585771560669| Acc: 11.428571428571429\n",
      "Epoch: 10 \n",
      "-----------\n",
      "Loss: 2.2234115600585938| Acc: 11.428571428571429\n",
      "Epoch: 11 \n",
      "-----------\n",
      "Loss: 2.222585439682007| Acc: 11.428571428571429\n",
      "Epoch: 12 \n",
      "-----------\n",
      "Loss: 2.219367504119873| Acc: 11.428571428571429\n",
      "Epoch: 13 \n",
      "-----------\n",
      "Loss: 2.218005895614624| Acc: 11.428571428571429\n",
      "Epoch: 14 \n",
      "-----------\n",
      "Loss: 2.215345859527588| Acc: 11.428571428571429\n",
      "Epoch: 15 \n",
      "-----------\n",
      "Loss: 2.2150654792785645| Acc: 11.428571428571429\n",
      "Epoch: 16 \n",
      "-----------\n",
      "Loss: 2.208056688308716| Acc: 11.428571428571429\n",
      "Epoch: 17 \n",
      "-----------\n",
      "Loss: 2.194323778152466| Acc: 11.428571428571429\n",
      "Epoch: 18 \n",
      "-----------\n",
      "Loss: 2.1936168670654297| Acc: 12.380952380952381\n",
      "Epoch: 19 \n",
      "-----------\n",
      "Loss: 2.20017409324646| Acc: 11.428571428571429\n",
      "Epoch: 20 \n",
      "-----------\n",
      "Loss: 2.1916558742523193| Acc: 11.428571428571429\n",
      "Epoch: 21 \n",
      "-----------\n",
      "Loss: 2.191478967666626| Acc: 11.428571428571429\n",
      "Epoch: 22 \n",
      "-----------\n",
      "Loss: 2.197415351867676| Acc: 10.476190476190476\n",
      "Epoch: 23 \n",
      "-----------\n",
      "Loss: 2.189511299133301| Acc: 11.428571428571429\n",
      "Epoch: 24 \n",
      "-----------\n",
      "Loss: 2.1882436275482178| Acc: 11.428571428571429\n",
      "Epoch: 25 \n",
      "-----------\n",
      "Loss: 2.185142993927002| Acc: 11.428571428571429\n",
      "Epoch: 26 \n",
      "-----------\n",
      "Loss: 2.1955807209014893| Acc: 10.476190476190476\n",
      "Epoch: 27 \n",
      "-----------\n",
      "Loss: 2.1678929328918457| Acc: 12.380952380952381\n",
      "Epoch: 28 \n",
      "-----------\n",
      "Loss: 2.1619338989257812| Acc: 12.380952380952381\n",
      "Epoch: 29 \n",
      "-----------\n",
      "Loss: 2.1104302406311035| Acc: 12.380952380952381\n",
      "Epoch: 30 \n",
      "-----------\n",
      "Loss: 2.058720111846924| Acc: 12.380952380952381\n",
      "Epoch: 31 \n",
      "-----------\n",
      "Loss: 2.0551369190216064| Acc: 11.428571428571429\n",
      "Epoch: 32 \n",
      "-----------\n",
      "Loss: 2.0591862201690674| Acc: 11.428571428571429\n",
      "Epoch: 33 \n",
      "-----------\n",
      "Loss: 2.0258071422576904| Acc: 13.333333333333334\n",
      "Epoch: 34 \n",
      "-----------\n",
      "Loss: 2.0183699131011963| Acc: 13.333333333333334\n",
      "Epoch: 35 \n",
      "-----------\n",
      "Loss: 2.0072457790374756| Acc: 14.285714285714285\n",
      "Epoch: 36 \n",
      "-----------\n",
      "Loss: 2.0051636695861816| Acc: 13.333333333333334\n",
      "Epoch: 37 \n",
      "-----------\n",
      "Loss: 2.0045340061187744| Acc: 13.333333333333334\n",
      "Epoch: 38 \n",
      "-----------\n",
      "Loss: 2.0140011310577393| Acc: 13.333333333333334\n",
      "Epoch: 39 \n",
      "-----------\n",
      "Loss: 2.004261016845703| Acc: 15.238095238095239\n",
      "Epoch: 40 \n",
      "-----------\n",
      "Loss: 2.034419536590576| Acc: 13.333333333333334\n",
      "Epoch: 41 \n",
      "-----------\n",
      "Loss: 1.995057225227356| Acc: 17.142857142857142\n",
      "Epoch: 42 \n",
      "-----------\n",
      "Loss: 1.99492609500885| Acc: 18.095238095238095\n",
      "Epoch: 43 \n",
      "-----------\n",
      "Loss: 1.9944604635238647| Acc: 20.0\n",
      "Epoch: 44 \n",
      "-----------\n",
      "Loss: 2.000152826309204| Acc: 15.238095238095239\n",
      "Epoch: 45 \n",
      "-----------\n",
      "Loss: 1.9922683238983154| Acc: 16.19047619047619\n",
      "Epoch: 46 \n",
      "-----------\n",
      "Loss: 1.9855499267578125| Acc: 17.142857142857142\n",
      "Epoch: 47 \n",
      "-----------\n",
      "Loss: 1.992098093032837| Acc: 19.047619047619047\n",
      "Epoch: 48 \n",
      "-----------\n",
      "Loss: 1.9889426231384277| Acc: 18.095238095238095\n",
      "Epoch: 49 \n",
      "-----------\n",
      "Loss: 1.9842606782913208| Acc: 17.142857142857142\n",
      "Epoch: 50 \n",
      "-----------\n",
      "Loss: 1.9834253787994385| Acc: 18.095238095238095\n",
      "Epoch: 51 \n",
      "-----------\n",
      "Loss: 1.9835929870605469| Acc: 18.095238095238095\n",
      "Epoch: 52 \n",
      "-----------\n",
      "Loss: 1.9827347993850708| Acc: 18.095238095238095\n",
      "Epoch: 53 \n",
      "-----------\n",
      "Loss: 1.9844764471054077| Acc: 17.142857142857142\n",
      "Epoch: 54 \n",
      "-----------\n",
      "Loss: 1.998294472694397| Acc: 14.285714285714285\n",
      "Epoch: 55 \n",
      "-----------\n",
      "Loss: 1.986610770225525| Acc: 20.0\n",
      "Epoch: 56 \n",
      "-----------\n",
      "Loss: 1.9830453395843506| Acc: 18.095238095238095\n",
      "Epoch: 57 \n",
      "-----------\n",
      "Loss: 2.0134425163269043| Acc: 11.428571428571429\n",
      "Epoch: 58 \n",
      "-----------\n",
      "Loss: 1.9814201593399048| Acc: 20.952380952380953\n",
      "Epoch: 59 \n",
      "-----------\n",
      "Loss: 1.9829342365264893| Acc: 18.095238095238095\n",
      "Epoch: 60 \n",
      "-----------\n",
      "Loss: 1.982643961906433| Acc: 20.952380952380953\n",
      "Epoch: 61 \n",
      "-----------\n",
      "Loss: 1.9803345203399658| Acc: 20.952380952380953\n",
      "Epoch: 62 \n",
      "-----------\n",
      "Loss: 1.9817676544189453| Acc: 18.095238095238095\n",
      "Epoch: 63 \n",
      "-----------\n",
      "Loss: 1.982192873954773| Acc: 20.0\n",
      "Epoch: 64 \n",
      "-----------\n",
      "Loss: 1.9804692268371582| Acc: 17.142857142857142\n",
      "Epoch: 65 \n",
      "-----------\n",
      "Loss: 1.9809907674789429| Acc: 18.095238095238095\n",
      "Epoch: 66 \n",
      "-----------\n",
      "Loss: 1.9873788356781006| Acc: 19.047619047619047\n",
      "Epoch: 67 \n",
      "-----------\n",
      "Loss: 1.9803718328475952| Acc: 20.0\n",
      "Epoch: 68 \n",
      "-----------\n",
      "Loss: 1.9767274856567383| Acc: 19.047619047619047\n",
      "Epoch: 69 \n",
      "-----------\n",
      "Loss: 1.9861401319503784| Acc: 20.952380952380953\n",
      "Epoch: 70 \n",
      "-----------\n",
      "Loss: 1.994532585144043| Acc: 17.142857142857142\n",
      "Epoch: 71 \n",
      "-----------\n",
      "Loss: 1.9836159944534302| Acc: 20.952380952380953\n",
      "Epoch: 72 \n",
      "-----------\n",
      "Loss: 1.9845490455627441| Acc: 19.047619047619047\n",
      "Epoch: 73 \n",
      "-----------\n",
      "Loss: 1.9996417760849| Acc: 20.952380952380953\n",
      "Epoch: 74 \n",
      "-----------\n",
      "Loss: 1.9907366037368774| Acc: 17.142857142857142\n",
      "Epoch: 75 \n",
      "-----------\n",
      "Loss: 2.038709878921509| Acc: 18.095238095238095\n",
      "Epoch: 76 \n",
      "-----------\n",
      "Loss: 1.9803599119186401| Acc: 23.809523809523807\n",
      "Epoch: 77 \n",
      "-----------\n",
      "Loss: 1.9688535928726196| Acc: 24.761904761904763\n",
      "Epoch: 78 \n",
      "-----------\n",
      "Loss: 1.9697842597961426| Acc: 22.857142857142858\n",
      "Epoch: 79 \n",
      "-----------\n",
      "Loss: 1.9686471223831177| Acc: 22.857142857142858\n",
      "Epoch: 80 \n",
      "-----------\n",
      "Loss: 1.9669747352600098| Acc: 22.857142857142858\n",
      "Epoch: 81 \n",
      "-----------\n",
      "Loss: 1.968235969543457| Acc: 22.857142857142858\n",
      "Epoch: 82 \n",
      "-----------\n",
      "Loss: 1.9716451168060303| Acc: 22.857142857142858\n",
      "Epoch: 83 \n",
      "-----------\n",
      "Loss: 1.9679869413375854| Acc: 23.809523809523807\n",
      "Epoch: 84 \n",
      "-----------\n",
      "Loss: 1.9693809747695923| Acc: 21.904761904761905\n",
      "Epoch: 85 \n",
      "-----------\n",
      "Loss: 1.969198226928711| Acc: 21.904761904761905\n",
      "Epoch: 86 \n",
      "-----------\n",
      "Loss: 1.96930992603302| Acc: 21.904761904761905\n",
      "Epoch: 87 \n",
      "-----------\n",
      "Loss: 1.9693249464035034| Acc: 21.904761904761905\n",
      "Epoch: 88 \n",
      "-----------\n",
      "Loss: 1.9689778089523315| Acc: 21.904761904761905\n",
      "Epoch: 89 \n",
      "-----------\n",
      "Loss: 1.9679304361343384| Acc: 21.904761904761905\n",
      "Epoch: 90 \n",
      "-----------\n",
      "Loss: 1.9675593376159668| Acc: 21.904761904761905\n",
      "Epoch: 91 \n",
      "-----------\n",
      "Loss: 1.967084288597107| Acc: 22.857142857142858\n",
      "Epoch: 92 \n",
      "-----------\n",
      "Loss: 1.9656115770339966| Acc: 22.857142857142858\n",
      "Epoch: 93 \n",
      "-----------\n",
      "Loss: 1.9667954444885254| Acc: 22.857142857142858\n",
      "Epoch: 94 \n",
      "-----------\n",
      "Loss: 1.964957356452942| Acc: 22.857142857142858\n",
      "Epoch: 95 \n",
      "-----------\n",
      "Loss: 1.9655098915100098| Acc: 23.809523809523807\n",
      "Epoch: 96 \n",
      "-----------\n",
      "Loss: 1.9753714799880981| Acc: 26.666666666666668\n",
      "Epoch: 97 \n",
      "-----------\n",
      "Loss: 1.9676077365875244| Acc: 23.809523809523807\n",
      "Epoch: 98 \n",
      "-----------\n",
      "Loss: 1.9666666984558105| Acc: 23.809523809523807\n",
      "Epoch: 99 \n",
      "-----------\n",
      "Loss: 1.9658066034317017| Acc: 23.809523809523807\n",
      "Epoch: 100 \n",
      "-----------\n",
      "Loss: 1.966431736946106| Acc: 23.809523809523807\n",
      "Epoch: 101 \n",
      "-----------\n",
      "Loss: 1.9658358097076416| Acc: 23.809523809523807\n",
      "Epoch: 102 \n",
      "-----------\n",
      "Loss: 1.9680167436599731| Acc: 20.952380952380953\n",
      "Epoch: 103 \n",
      "-----------\n",
      "Loss: 1.9665087461471558| Acc: 23.809523809523807\n",
      "Epoch: 104 \n",
      "-----------\n",
      "Loss: 1.9650403261184692| Acc: 23.809523809523807\n",
      "Epoch: 105 \n",
      "-----------\n",
      "Loss: 1.9622650146484375| Acc: 24.761904761904763\n",
      "Epoch: 106 \n",
      "-----------\n",
      "Loss: 1.9639486074447632| Acc: 23.809523809523807\n",
      "Epoch: 107 \n",
      "-----------\n",
      "Loss: 1.9634816646575928| Acc: 23.809523809523807\n",
      "Epoch: 108 \n",
      "-----------\n",
      "Loss: 1.9474114179611206| Acc: 25.71428571428571\n",
      "Epoch: 109 \n",
      "-----------\n",
      "Loss: 1.9337855577468872| Acc: 25.71428571428571\n",
      "Epoch: 110 \n",
      "-----------\n",
      "Loss: 1.9349853992462158| Acc: 27.61904761904762\n",
      "Epoch: 111 \n",
      "-----------\n",
      "Loss: 1.9669768810272217| Acc: 23.809523809523807\n",
      "Epoch: 112 \n",
      "-----------\n",
      "Loss: 1.9342073202133179| Acc: 24.761904761904763\n",
      "Epoch: 113 \n",
      "-----------\n",
      "Loss: 1.9791463613510132| Acc: 23.809523809523807\n",
      "Epoch: 114 \n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.9353374242782593| Acc: 25.71428571428571\n",
      "Epoch: 115 \n",
      "-----------\n",
      "Loss: 1.9382078647613525| Acc: 29.523809523809526\n",
      "Epoch: 116 \n",
      "-----------\n",
      "Loss: 1.934908151626587| Acc: 28.57142857142857\n",
      "Epoch: 117 \n",
      "-----------\n",
      "Loss: 1.9380221366882324| Acc: 30.476190476190478\n",
      "Epoch: 118 \n",
      "-----------\n",
      "Loss: 1.9360750913619995| Acc: 27.61904761904762\n",
      "Epoch: 119 \n",
      "-----------\n",
      "Loss: 1.968184232711792| Acc: 26.666666666666668\n",
      "Epoch: 120 \n",
      "-----------\n",
      "Loss: 1.9502816200256348| Acc: 31.428571428571427\n",
      "Epoch: 121 \n",
      "-----------\n",
      "Loss: 1.939582347869873| Acc: 31.428571428571427\n",
      "Epoch: 122 \n",
      "-----------\n",
      "Loss: 1.9304579496383667| Acc: 32.38095238095238\n",
      "Epoch: 123 \n",
      "-----------\n",
      "Loss: 1.9329776763916016| Acc: 32.38095238095238\n",
      "Epoch: 124 \n",
      "-----------\n",
      "Loss: 1.9354814291000366| Acc: 26.666666666666668\n",
      "Epoch: 125 \n",
      "-----------\n",
      "Loss: 1.9412636756896973| Acc: 30.476190476190478\n",
      "Epoch: 126 \n",
      "-----------\n",
      "Loss: 1.9345484972000122| Acc: 28.57142857142857\n",
      "Epoch: 127 \n",
      "-----------\n",
      "Loss: 1.931901454925537| Acc: 29.523809523809526\n",
      "Epoch: 128 \n",
      "-----------\n",
      "Loss: 1.9424444437026978| Acc: 34.285714285714285\n",
      "Epoch: 129 \n",
      "-----------\n",
      "Loss: 1.9335447549819946| Acc: 27.61904761904762\n",
      "Epoch: 130 \n",
      "-----------\n",
      "Loss: 1.9334044456481934| Acc: 27.61904761904762\n",
      "Epoch: 131 \n",
      "-----------\n",
      "Loss: 1.943756103515625| Acc: 26.666666666666668\n",
      "Epoch: 132 \n",
      "-----------\n",
      "Loss: 1.9426274299621582| Acc: 31.428571428571427\n",
      "Epoch: 133 \n",
      "-----------\n",
      "Loss: 1.9355134963989258| Acc: 26.666666666666668\n",
      "Epoch: 134 \n",
      "-----------\n",
      "Loss: 1.934726357460022| Acc: 26.666666666666668\n",
      "Epoch: 135 \n",
      "-----------\n",
      "Loss: 1.9417076110839844| Acc: 27.61904761904762\n",
      "Epoch: 136 \n",
      "-----------\n",
      "Loss: 1.9285446405410767| Acc: 32.38095238095238\n",
      "Epoch: 137 \n",
      "-----------\n",
      "Loss: 1.9351420402526855| Acc: 30.476190476190478\n",
      "Epoch: 138 \n",
      "-----------\n",
      "Loss: 1.9339213371276855| Acc: 27.61904761904762\n",
      "Epoch: 139 \n",
      "-----------\n",
      "Loss: 1.9384859800338745| Acc: 28.57142857142857\n",
      "Epoch: 140 \n",
      "-----------\n",
      "Loss: 1.9334577322006226| Acc: 28.57142857142857\n",
      "Epoch: 141 \n",
      "-----------\n",
      "Loss: 1.9309182167053223| Acc: 27.61904761904762\n",
      "Epoch: 142 \n",
      "-----------\n",
      "Loss: 1.9303677082061768| Acc: 27.61904761904762\n",
      "Epoch: 143 \n",
      "-----------\n",
      "Loss: 1.9301718473434448| Acc: 27.61904761904762\n",
      "Epoch: 144 \n",
      "-----------\n",
      "Loss: 1.9300683736801147| Acc: 28.57142857142857\n",
      "Epoch: 145 \n",
      "-----------\n",
      "Loss: 1.9294203519821167| Acc: 28.57142857142857\n",
      "Epoch: 146 \n",
      "-----------\n",
      "Loss: 1.9287463426589966| Acc: 29.523809523809526\n",
      "Epoch: 147 \n",
      "-----------\n",
      "Loss: 1.9287973642349243| Acc: 28.57142857142857\n",
      "Epoch: 148 \n",
      "-----------\n",
      "Loss: 1.9382164478302002| Acc: 33.33333333333333\n",
      "Epoch: 149 \n",
      "-----------\n",
      "Loss: 1.939756155014038| Acc: 32.38095238095238\n",
      "Epoch: 150 \n",
      "-----------\n",
      "Loss: 1.986539363861084| Acc: 27.61904761904762\n",
      "Epoch: 151 \n",
      "-----------\n",
      "Loss: 1.9607144594192505| Acc: 30.476190476190478\n",
      "Epoch: 152 \n",
      "-----------\n",
      "Loss: 1.9271677732467651| Acc: 34.285714285714285\n",
      "Epoch: 153 \n",
      "-----------\n",
      "Loss: 1.9262930154800415| Acc: 34.285714285714285\n",
      "Epoch: 154 \n",
      "-----------\n",
      "Loss: 1.928647756576538| Acc: 29.523809523809526\n",
      "Epoch: 155 \n",
      "-----------\n",
      "Loss: 1.929174542427063| Acc: 29.523809523809526\n",
      "Epoch: 156 \n",
      "-----------\n",
      "Loss: 1.9283630847930908| Acc: 29.523809523809526\n",
      "Epoch: 157 \n",
      "-----------\n",
      "Loss: 1.9288278818130493| Acc: 33.33333333333333\n",
      "Epoch: 158 \n",
      "-----------\n",
      "Loss: 1.9408411979675293| Acc: 29.523809523809526\n",
      "Epoch: 159 \n",
      "-----------\n",
      "Loss: 1.9287806749343872| Acc: 29.523809523809526\n",
      "Epoch: 160 \n",
      "-----------\n",
      "Loss: 1.9307255744934082| Acc: 29.523809523809526\n",
      "Epoch: 161 \n",
      "-----------\n",
      "Loss: 1.926230549812317| Acc: 31.428571428571427\n",
      "Epoch: 162 \n",
      "-----------\n",
      "Loss: 1.9248223304748535| Acc: 35.23809523809524\n",
      "Epoch: 163 \n",
      "-----------\n",
      "Loss: 1.9261646270751953| Acc: 30.476190476190478\n",
      "Epoch: 164 \n",
      "-----------\n",
      "Loss: 1.92592453956604| Acc: 29.523809523809526\n",
      "Epoch: 165 \n",
      "-----------\n",
      "Loss: 1.946686863899231| Acc: 29.523809523809526\n",
      "Epoch: 166 \n",
      "-----------\n",
      "Loss: 1.929649829864502| Acc: 32.38095238095238\n",
      "Epoch: 167 \n",
      "-----------\n",
      "Loss: 1.9240940809249878| Acc: 37.142857142857146\n",
      "Epoch: 168 \n",
      "-----------\n",
      "Loss: 1.927738904953003| Acc: 35.23809523809524\n",
      "Epoch: 169 \n",
      "-----------\n",
      "Loss: 1.9252794981002808| Acc: 34.285714285714285\n",
      "Epoch: 170 \n",
      "-----------\n",
      "Loss: 1.9240269660949707| Acc: 37.142857142857146\n",
      "Epoch: 171 \n",
      "-----------\n",
      "Loss: 1.9237947463989258| Acc: 36.19047619047619\n",
      "Epoch: 172 \n",
      "-----------\n",
      "Loss: 1.9248754978179932| Acc: 36.19047619047619\n",
      "Epoch: 173 \n",
      "-----------\n",
      "Loss: 1.9239431619644165| Acc: 36.19047619047619\n",
      "Epoch: 174 \n",
      "-----------\n",
      "Loss: 1.9240154027938843| Acc: 36.19047619047619\n",
      "Epoch: 175 \n",
      "-----------\n",
      "Loss: 1.9285794496536255| Acc: 32.38095238095238\n",
      "Epoch: 176 \n",
      "-----------\n",
      "Loss: 1.9268076419830322| Acc: 32.38095238095238\n",
      "Epoch: 177 \n",
      "-----------\n",
      "Loss: 1.9205480813980103| Acc: 36.19047619047619\n",
      "Epoch: 178 \n",
      "-----------\n",
      "Loss: 1.9241405725479126| Acc: 33.33333333333333\n",
      "Epoch: 179 \n",
      "-----------\n",
      "Loss: 1.924315333366394| Acc: 33.33333333333333\n",
      "Epoch: 180 \n",
      "-----------\n",
      "Loss: 1.9234089851379395| Acc: 34.285714285714285\n",
      "Epoch: 181 \n",
      "-----------\n",
      "Loss: 1.9299921989440918| Acc: 31.428571428571427\n",
      "Epoch: 182 \n",
      "-----------\n",
      "Loss: 1.9196826219558716| Acc: 37.142857142857146\n",
      "Epoch: 183 \n",
      "-----------\n",
      "Loss: 1.9252911806106567| Acc: 32.38095238095238\n",
      "Epoch: 184 \n",
      "-----------\n",
      "Loss: 1.922884464263916| Acc: 36.19047619047619\n",
      "Epoch: 185 \n",
      "-----------\n",
      "Loss: 1.9223884344100952| Acc: 36.19047619047619\n",
      "Epoch: 186 \n",
      "-----------\n",
      "Loss: 1.922448754310608| Acc: 35.23809523809524\n",
      "Epoch: 187 \n",
      "-----------\n",
      "Loss: 1.9244959354400635| Acc: 34.285714285714285\n",
      "Epoch: 188 \n",
      "-----------\n",
      "Loss: 1.924674391746521| Acc: 32.38095238095238\n",
      "Epoch: 189 \n",
      "-----------\n",
      "Loss: 1.9220376014709473| Acc: 36.19047619047619\n",
      "Epoch: 190 \n",
      "-----------\n",
      "Loss: 1.9239476919174194| Acc: 33.33333333333333\n",
      "Epoch: 191 \n",
      "-----------\n",
      "Loss: 1.9267436265945435| Acc: 34.285714285714285\n",
      "Epoch: 192 \n",
      "-----------\n",
      "Loss: 1.9200282096862793| Acc: 37.142857142857146\n",
      "Epoch: 193 \n",
      "-----------\n",
      "Loss: 1.935444951057434| Acc: 36.19047619047619\n",
      "Epoch: 194 \n",
      "-----------\n",
      "Loss: 1.921416997909546| Acc: 36.19047619047619\n",
      "Epoch: 195 \n",
      "-----------\n",
      "Loss: 1.9417297840118408| Acc: 30.476190476190478\n",
      "Epoch: 196 \n",
      "-----------\n",
      "Loss: 1.9257704019546509| Acc: 35.23809523809524\n",
      "Epoch: 197 \n",
      "-----------\n",
      "Loss: 1.9212646484375| Acc: 31.428571428571427\n",
      "Epoch: 198 \n",
      "-----------\n",
      "Loss: 1.9220647811889648| Acc: 36.19047619047619\n",
      "Epoch: 199 \n",
      "-----------\n",
      "Loss: 1.921457290649414| Acc: 35.23809523809524\n",
      "Epoch: 200 \n",
      "-----------\n",
      "Loss: 1.9456241130828857| Acc: 30.476190476190478\n",
      "Epoch: 201 \n",
      "-----------\n",
      "Loss: 1.9211232662200928| Acc: 36.19047619047619\n",
      "Epoch: 202 \n",
      "-----------\n",
      "Loss: 1.9194320440292358| Acc: 38.095238095238095\n",
      "Epoch: 203 \n",
      "-----------\n",
      "Loss: 1.9191066026687622| Acc: 38.095238095238095\n",
      "Epoch: 204 \n",
      "-----------\n",
      "Loss: 1.9206641912460327| Acc: 37.142857142857146\n",
      "Epoch: 205 \n",
      "-----------\n",
      "Loss: 1.92801034450531| Acc: 36.19047619047619\n",
      "Epoch: 206 \n",
      "-----------\n",
      "Loss: 1.9158356189727783| Acc: 39.04761904761905\n",
      "Epoch: 207 \n",
      "-----------\n",
      "Loss: 1.9115726947784424| Acc: 29.523809523809526\n",
      "Epoch: 208 \n",
      "-----------\n",
      "Loss: 1.9044854640960693| Acc: 29.523809523809526\n",
      "Epoch: 209 \n",
      "-----------\n",
      "Loss: 1.9227793216705322| Acc: 25.71428571428571\n",
      "Epoch: 210 \n",
      "-----------\n",
      "Loss: 1.9023536443710327| Acc: 28.57142857142857\n",
      "Epoch: 211 \n",
      "-----------\n",
      "Loss: 1.9022635221481323| Acc: 28.57142857142857\n",
      "Epoch: 212 \n",
      "-----------\n",
      "Loss: 1.9143126010894775| Acc: 25.71428571428571\n",
      "Epoch: 213 \n",
      "-----------\n",
      "Loss: 1.8902335166931152| Acc: 29.523809523809526\n",
      "Epoch: 214 \n",
      "-----------\n",
      "Loss: 1.8933050632476807| Acc: 29.523809523809526\n",
      "Epoch: 215 \n",
      "-----------\n",
      "Loss: 1.891784906387329| Acc: 29.523809523809526\n",
      "Epoch: 216 \n",
      "-----------\n",
      "Loss: 1.8914471864700317| Acc: 30.476190476190478\n",
      "Epoch: 217 \n",
      "-----------\n",
      "Loss: 1.8928254842758179| Acc: 27.61904761904762\n",
      "Epoch: 218 \n",
      "-----------\n",
      "Loss: 1.8889988660812378| Acc: 30.476190476190478\n",
      "Epoch: 219 \n",
      "-----------\n",
      "Loss: 1.8920892477035522| Acc: 29.523809523809526\n",
      "Epoch: 220 \n",
      "-----------\n",
      "Loss: 1.8909227848052979| Acc: 31.428571428571427\n",
      "Epoch: 221 \n",
      "-----------\n",
      "Loss: 1.8913452625274658| Acc: 31.428571428571427\n",
      "Epoch: 222 \n",
      "-----------\n",
      "Loss: 1.8922946453094482| Acc: 28.57142857142857\n",
      "Epoch: 223 \n",
      "-----------\n",
      "Loss: 1.8925471305847168| Acc: 28.57142857142857\n",
      "Epoch: 224 \n",
      "-----------\n",
      "Loss: 1.897377848625183| Acc: 30.476190476190478\n",
      "Epoch: 225 \n",
      "-----------\n",
      "Loss: 1.8869683742523193| Acc: 35.23809523809524\n",
      "Epoch: 226 \n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.888165831565857| Acc: 29.523809523809526\n",
      "Epoch: 227 \n",
      "-----------\n",
      "Loss: 1.8872971534729004| Acc: 33.33333333333333\n",
      "Epoch: 228 \n",
      "-----------\n",
      "Loss: 1.8895806074142456| Acc: 31.428571428571427\n",
      "Epoch: 229 \n",
      "-----------\n",
      "Loss: 1.8965202569961548| Acc: 40.0\n",
      "Epoch: 230 \n",
      "-----------\n",
      "Loss: 1.9154558181762695| Acc: 30.476190476190478\n",
      "Epoch: 231 \n",
      "-----------\n",
      "Loss: 1.8922851085662842| Acc: 34.285714285714285\n",
      "Epoch: 232 \n",
      "-----------\n",
      "Loss: 1.885780930519104| Acc: 30.476190476190478\n",
      "Epoch: 233 \n",
      "-----------\n",
      "Loss: 1.9010943174362183| Acc: 27.61904761904762\n",
      "Epoch: 234 \n",
      "-----------\n",
      "Loss: 1.8865224123001099| Acc: 31.428571428571427\n",
      "Epoch: 235 \n",
      "-----------\n",
      "Loss: 1.88616943359375| Acc: 30.476190476190478\n",
      "Epoch: 236 \n",
      "-----------\n",
      "Loss: 1.879544734954834| Acc: 33.33333333333333\n",
      "Epoch: 237 \n",
      "-----------\n",
      "Loss: 1.8746131658554077| Acc: 34.285714285714285\n",
      "Epoch: 238 \n",
      "-----------\n",
      "Loss: 1.8767870664596558| Acc: 35.23809523809524\n",
      "Epoch: 239 \n",
      "-----------\n",
      "Loss: 1.8760435581207275| Acc: 36.19047619047619\n",
      "Epoch: 240 \n",
      "-----------\n",
      "Loss: 1.8820182085037231| Acc: 34.285714285714285\n",
      "Epoch: 241 \n",
      "-----------\n",
      "Loss: 1.8769383430480957| Acc: 36.19047619047619\n",
      "Epoch: 242 \n",
      "-----------\n",
      "Loss: 1.8755207061767578| Acc: 36.19047619047619\n",
      "Epoch: 243 \n",
      "-----------\n",
      "Loss: 1.8772308826446533| Acc: 29.523809523809526\n",
      "Epoch: 244 \n",
      "-----------\n",
      "Loss: 1.877517580986023| Acc: 36.19047619047619\n",
      "Epoch: 245 \n",
      "-----------\n",
      "Loss: 1.8782422542572021| Acc: 33.33333333333333\n",
      "Epoch: 246 \n",
      "-----------\n",
      "Loss: 1.876930832862854| Acc: 35.23809523809524\n",
      "Epoch: 247 \n",
      "-----------\n",
      "Loss: 1.8773539066314697| Acc: 35.23809523809524\n",
      "Epoch: 248 \n",
      "-----------\n",
      "Loss: 1.8768861293792725| Acc: 35.23809523809524\n",
      "Epoch: 249 \n",
      "-----------\n",
      "Loss: 1.8774183988571167| Acc: 36.19047619047619\n",
      "Epoch: 250 \n",
      "-----------\n",
      "Loss: 1.8766378164291382| Acc: 35.23809523809524\n",
      "Epoch: 251 \n",
      "-----------\n",
      "Loss: 1.8771369457244873| Acc: 34.285714285714285\n",
      "Epoch: 252 \n",
      "-----------\n",
      "Loss: 1.8759844303131104| Acc: 34.285714285714285\n",
      "Epoch: 253 \n",
      "-----------\n",
      "Loss: 1.8766130208969116| Acc: 36.19047619047619\n",
      "Epoch: 254 \n",
      "-----------\n",
      "Loss: 1.8773449659347534| Acc: 32.38095238095238\n",
      "Epoch: 255 \n",
      "-----------\n",
      "Loss: 1.8751558065414429| Acc: 37.142857142857146\n",
      "Epoch: 256 \n",
      "-----------\n",
      "Loss: 1.8753528594970703| Acc: 36.19047619047619\n",
      "Epoch: 257 \n",
      "-----------\n",
      "Loss: 1.87503981590271| Acc: 34.285714285714285\n",
      "Epoch: 258 \n",
      "-----------\n",
      "Loss: 1.8757045269012451| Acc: 35.23809523809524\n",
      "Epoch: 259 \n",
      "-----------\n",
      "Loss: 1.875462293624878| Acc: 35.23809523809524\n",
      "Epoch: 260 \n",
      "-----------\n",
      "Loss: 1.8751119375228882| Acc: 35.23809523809524\n",
      "Epoch: 261 \n",
      "-----------\n",
      "Loss: 1.875422716140747| Acc: 35.23809523809524\n",
      "Epoch: 262 \n",
      "-----------\n",
      "Loss: 1.886157512664795| Acc: 32.38095238095238\n",
      "Epoch: 263 \n",
      "-----------\n",
      "Loss: 1.8758314847946167| Acc: 35.23809523809524\n",
      "Epoch: 264 \n",
      "-----------\n",
      "Loss: 1.8757073879241943| Acc: 35.23809523809524\n",
      "Epoch: 265 \n",
      "-----------\n",
      "Loss: 1.9084938764572144| Acc: 40.0\n",
      "Epoch: 266 \n",
      "-----------\n",
      "Loss: 1.9317419528961182| Acc: 40.0\n",
      "Epoch: 267 \n",
      "-----------\n",
      "Loss: 1.893371820449829| Acc: 35.23809523809524\n",
      "Epoch: 268 \n",
      "-----------\n",
      "Loss: 1.9129663705825806| Acc: 31.428571428571427\n",
      "Epoch: 269 \n",
      "-----------\n",
      "Loss: 1.8720470666885376| Acc: 34.285714285714285\n",
      "Epoch: 270 \n",
      "-----------\n",
      "Loss: 1.8728159666061401| Acc: 34.285714285714285\n",
      "Epoch: 271 \n",
      "-----------\n",
      "Loss: 1.8742749691009521| Acc: 35.23809523809524\n",
      "Epoch: 272 \n",
      "-----------\n",
      "Loss: 1.8737760782241821| Acc: 33.33333333333333\n",
      "Epoch: 273 \n",
      "-----------\n",
      "Loss: 1.8738311529159546| Acc: 33.33333333333333\n",
      "Epoch: 274 \n",
      "-----------\n",
      "Loss: 1.8738915920257568| Acc: 31.428571428571427\n",
      "Epoch: 275 \n",
      "-----------\n",
      "Loss: 1.8737620115280151| Acc: 34.285714285714285\n",
      "Epoch: 276 \n",
      "-----------\n",
      "Loss: 1.8735159635543823| Acc: 37.142857142857146\n",
      "Epoch: 277 \n",
      "-----------\n",
      "Loss: 1.87257981300354| Acc: 30.476190476190478\n",
      "Epoch: 278 \n",
      "-----------\n",
      "Loss: 1.8724510669708252| Acc: 35.23809523809524\n",
      "Epoch: 279 \n",
      "-----------\n",
      "Loss: 1.8725422620773315| Acc: 36.19047619047619\n",
      "Epoch: 280 \n",
      "-----------\n",
      "Loss: 1.872550368309021| Acc: 36.19047619047619\n",
      "Epoch: 281 \n",
      "-----------\n",
      "Loss: 1.882703185081482| Acc: 34.285714285714285\n",
      "Epoch: 282 \n",
      "-----------\n",
      "Loss: 1.8735870122909546| Acc: 32.38095238095238\n",
      "Epoch: 283 \n",
      "-----------\n",
      "Loss: 1.9042571783065796| Acc: 36.19047619047619\n",
      "Epoch: 284 \n",
      "-----------\n",
      "Loss: 1.901503086090088| Acc: 38.095238095238095\n",
      "Epoch: 285 \n",
      "-----------\n",
      "Loss: 1.9037363529205322| Acc: 38.095238095238095\n",
      "Epoch: 286 \n",
      "-----------\n",
      "Loss: 1.9016200304031372| Acc: 40.0\n",
      "Epoch: 287 \n",
      "-----------\n",
      "Loss: 1.8720357418060303| Acc: 37.142857142857146\n",
      "Epoch: 288 \n",
      "-----------\n",
      "Loss: 1.8717398643493652| Acc: 34.285714285714285\n",
      "Epoch: 289 \n",
      "-----------\n",
      "Loss: 1.8719195127487183| Acc: 34.285714285714285\n",
      "Epoch: 290 \n",
      "-----------\n",
      "Loss: 1.87204110622406| Acc: 35.23809523809524\n",
      "Epoch: 291 \n",
      "-----------\n",
      "Loss: 1.8715707063674927| Acc: 36.19047619047619\n",
      "Epoch: 292 \n",
      "-----------\n",
      "Loss: 1.8719205856323242| Acc: 37.142857142857146\n",
      "Epoch: 293 \n",
      "-----------\n",
      "Loss: 1.872096061706543| Acc: 32.38095238095238\n",
      "Epoch: 294 \n",
      "-----------\n",
      "Loss: 1.871849536895752| Acc: 35.23809523809524\n",
      "Epoch: 295 \n",
      "-----------\n",
      "Loss: 1.871156930923462| Acc: 36.19047619047619\n",
      "Epoch: 296 \n",
      "-----------\n",
      "Loss: 1.871459722518921| Acc: 36.19047619047619\n",
      "Epoch: 297 \n",
      "-----------\n",
      "Loss: 1.8717198371887207| Acc: 35.23809523809524\n",
      "Epoch: 298 \n",
      "-----------\n",
      "Loss: 1.8718541860580444| Acc: 36.19047619047619\n",
      "Epoch: 299 \n",
      "-----------\n",
      "Loss: 1.8714985847473145| Acc: 32.38095238095238\n",
      "Epoch: 300 \n",
      "-----------\n",
      "Loss: 1.8713932037353516| Acc: 34.285714285714285\n",
      "Epoch: 301 \n",
      "-----------\n",
      "Loss: 1.8710530996322632| Acc: 34.285714285714285\n",
      "Epoch: 302 \n",
      "-----------\n",
      "Loss: 1.870328426361084| Acc: 33.33333333333333\n",
      "Epoch: 303 \n",
      "-----------\n",
      "Loss: 1.8688926696777344| Acc: 33.33333333333333\n",
      "Epoch: 304 \n",
      "-----------\n",
      "Loss: 1.865437388420105| Acc: 33.33333333333333\n",
      "Epoch: 305 \n",
      "-----------\n",
      "Loss: 1.8648555278778076| Acc: 31.428571428571427\n",
      "Epoch: 306 \n",
      "-----------\n",
      "Loss: 1.9029724597930908| Acc: 29.523809523809526\n",
      "Epoch: 307 \n",
      "-----------\n",
      "Loss: 1.9147206544876099| Acc: 31.428571428571427\n",
      "Epoch: 308 \n",
      "-----------\n",
      "Loss: 1.8860081434249878| Acc: 30.476190476190478\n",
      "Epoch: 309 \n",
      "-----------\n",
      "Loss: 1.8705954551696777| Acc: 32.38095238095238\n",
      "Epoch: 310 \n",
      "-----------\n",
      "Loss: 1.8738641738891602| Acc: 32.38095238095238\n",
      "Epoch: 311 \n",
      "-----------\n",
      "Loss: 1.8711023330688477| Acc: 32.38095238095238\n",
      "Epoch: 312 \n",
      "-----------\n",
      "Loss: 1.8694205284118652| Acc: 31.428571428571427\n",
      "Epoch: 313 \n",
      "-----------\n",
      "Loss: 1.8704688549041748| Acc: 32.38095238095238\n",
      "Epoch: 314 \n",
      "-----------\n",
      "Loss: 1.8628263473510742| Acc: 32.38095238095238\n",
      "Epoch: 315 \n",
      "-----------\n",
      "Loss: 1.8635740280151367| Acc: 34.285714285714285\n",
      "Epoch: 316 \n",
      "-----------\n",
      "Loss: 1.8753992319107056| Acc: 29.523809523809526\n",
      "Epoch: 317 \n",
      "-----------\n",
      "Loss: 1.8631401062011719| Acc: 35.23809523809524\n",
      "Epoch: 318 \n",
      "-----------\n",
      "Loss: 1.8614529371261597| Acc: 34.285714285714285\n",
      "Epoch: 319 \n",
      "-----------\n",
      "Loss: 1.8624811172485352| Acc: 35.23809523809524\n",
      "Epoch: 320 \n",
      "-----------\n",
      "Loss: 1.86139714717865| Acc: 35.23809523809524\n",
      "Epoch: 321 \n",
      "-----------\n",
      "Loss: 1.8613992929458618| Acc: 35.23809523809524\n",
      "Epoch: 322 \n",
      "-----------\n",
      "Loss: 1.8612619638442993| Acc: 35.23809523809524\n",
      "Epoch: 323 \n",
      "-----------\n",
      "Loss: 1.860900640487671| Acc: 35.23809523809524\n",
      "Epoch: 324 \n",
      "-----------\n",
      "Loss: 1.8606693744659424| Acc: 35.23809523809524\n",
      "Epoch: 325 \n",
      "-----------\n",
      "Loss: 1.8606839179992676| Acc: 35.23809523809524\n",
      "Epoch: 326 \n",
      "-----------\n",
      "Loss: 1.8603999614715576| Acc: 35.23809523809524\n",
      "Epoch: 327 \n",
      "-----------\n",
      "Loss: 1.8603789806365967| Acc: 35.23809523809524\n",
      "Epoch: 328 \n",
      "-----------\n",
      "Loss: 1.8606153726577759| Acc: 35.23809523809524\n",
      "Epoch: 329 \n",
      "-----------\n",
      "Loss: 1.8597391843795776| Acc: 34.285714285714285\n",
      "Epoch: 330 \n",
      "-----------\n",
      "Loss: 1.8602240085601807| Acc: 35.23809523809524\n",
      "Epoch: 331 \n",
      "-----------\n",
      "Loss: 1.8599387407302856| Acc: 35.23809523809524\n",
      "Epoch: 332 \n",
      "-----------\n",
      "Loss: 1.8597463369369507| Acc: 35.23809523809524\n",
      "Epoch: 333 \n",
      "-----------\n",
      "Loss: 1.8594070672988892| Acc: 34.285714285714285\n",
      "Epoch: 334 \n",
      "-----------\n",
      "Loss: 1.8590810298919678| Acc: 34.285714285714285\n",
      "Epoch: 335 \n",
      "-----------\n",
      "Loss: 1.8595519065856934| Acc: 34.285714285714285\n",
      "Epoch: 336 \n",
      "-----------\n",
      "Loss: 1.8590446710586548| Acc: 34.285714285714285\n",
      "Epoch: 337 \n",
      "-----------\n",
      "Loss: 1.858827829360962| Acc: 35.23809523809524\n",
      "Epoch: 338 \n",
      "-----------\n",
      "Loss: 1.859068512916565| Acc: 36.19047619047619\n",
      "Epoch: 339 \n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.8588248491287231| Acc: 36.19047619047619\n",
      "Epoch: 340 \n",
      "-----------\n",
      "Loss: 1.8584418296813965| Acc: 36.19047619047619\n",
      "Epoch: 341 \n",
      "-----------\n",
      "Loss: 1.8584568500518799| Acc: 36.19047619047619\n",
      "Epoch: 342 \n",
      "-----------\n",
      "Loss: 1.8583500385284424| Acc: 35.23809523809524\n",
      "Epoch: 343 \n",
      "-----------\n",
      "Loss: 1.8583670854568481| Acc: 36.19047619047619\n",
      "Epoch: 344 \n",
      "-----------\n",
      "Loss: 1.8587467670440674| Acc: 34.285714285714285\n",
      "Epoch: 345 \n",
      "-----------\n",
      "Loss: 1.8583056926727295| Acc: 36.19047619047619\n",
      "Epoch: 346 \n",
      "-----------\n",
      "Loss: 1.857546091079712| Acc: 37.142857142857146\n",
      "Epoch: 347 \n",
      "-----------\n",
      "Loss: 1.8578486442565918| Acc: 36.19047619047619\n",
      "Epoch: 348 \n",
      "-----------\n",
      "Loss: 1.8571549654006958| Acc: 37.142857142857146\n",
      "Epoch: 349 \n",
      "-----------\n",
      "Loss: 1.8602761030197144| Acc: 33.33333333333333\n",
      "Epoch: 350 \n",
      "-----------\n",
      "Loss: 1.8651400804519653| Acc: 36.19047619047619\n",
      "Epoch: 351 \n",
      "-----------\n",
      "Loss: 1.8578656911849976| Acc: 35.23809523809524\n",
      "Epoch: 352 \n",
      "-----------\n",
      "Loss: 1.877032995223999| Acc: 33.33333333333333\n",
      "Epoch: 353 \n",
      "-----------\n",
      "Loss: 1.8650214672088623| Acc: 37.142857142857146\n",
      "Epoch: 354 \n",
      "-----------\n",
      "Loss: 1.8656764030456543| Acc: 35.23809523809524\n",
      "Epoch: 355 \n",
      "-----------\n",
      "Loss: 1.856609582901001| Acc: 35.23809523809524\n",
      "Epoch: 356 \n",
      "-----------\n",
      "Loss: 1.8578630685806274| Acc: 34.285714285714285\n",
      "Epoch: 357 \n",
      "-----------\n",
      "Loss: 1.8605587482452393| Acc: 33.33333333333333\n",
      "Epoch: 358 \n",
      "-----------\n",
      "Loss: 1.856549620628357| Acc: 37.142857142857146\n",
      "Epoch: 359 \n",
      "-----------\n",
      "Loss: 1.8562065362930298| Acc: 35.23809523809524\n",
      "Epoch: 360 \n",
      "-----------\n",
      "Loss: 1.8571871519088745| Acc: 33.33333333333333\n",
      "Epoch: 361 \n",
      "-----------\n",
      "Loss: 1.871927261352539| Acc: 40.0\n",
      "Epoch: 362 \n",
      "-----------\n",
      "Loss: 1.8646172285079956| Acc: 36.19047619047619\n",
      "Epoch: 363 \n",
      "-----------\n",
      "Loss: 1.8601306676864624| Acc: 33.33333333333333\n",
      "Epoch: 364 \n",
      "-----------\n",
      "Loss: 1.8617496490478516| Acc: 32.38095238095238\n",
      "Epoch: 365 \n",
      "-----------\n",
      "Loss: 1.8824023008346558| Acc: 33.33333333333333\n",
      "Epoch: 366 \n",
      "-----------\n",
      "Loss: 1.8535149097442627| Acc: 41.904761904761905\n",
      "Epoch: 367 \n",
      "-----------\n",
      "Loss: 1.8557771444320679| Acc: 34.285714285714285\n",
      "Epoch: 368 \n",
      "-----------\n",
      "Loss: 1.8552120923995972| Acc: 35.23809523809524\n",
      "Epoch: 369 \n",
      "-----------\n",
      "Loss: 1.8550313711166382| Acc: 35.23809523809524\n",
      "Epoch: 370 \n",
      "-----------\n",
      "Loss: 1.855233073234558| Acc: 36.19047619047619\n",
      "Epoch: 371 \n",
      "-----------\n",
      "Loss: 1.855712890625| Acc: 36.19047619047619\n",
      "Epoch: 372 \n",
      "-----------\n",
      "Loss: 1.8966909646987915| Acc: 33.33333333333333\n",
      "Epoch: 373 \n",
      "-----------\n",
      "Loss: 1.8517155647277832| Acc: 37.142857142857146\n",
      "Epoch: 374 \n",
      "-----------\n",
      "Loss: 1.8527652025222778| Acc: 36.19047619047619\n",
      "Epoch: 375 \n",
      "-----------\n",
      "Loss: 1.853724479675293| Acc: 35.23809523809524\n",
      "Epoch: 376 \n",
      "-----------\n",
      "Loss: 1.8548883199691772| Acc: 35.23809523809524\n",
      "Epoch: 377 \n",
      "-----------\n",
      "Loss: 1.8561644554138184| Acc: 36.19047619047619\n",
      "Epoch: 378 \n",
      "-----------\n",
      "Loss: 1.8600668907165527| Acc: 35.23809523809524\n",
      "Epoch: 379 \n",
      "-----------\n",
      "Loss: 1.857858419418335| Acc: 34.285714285714285\n",
      "Epoch: 380 \n",
      "-----------\n",
      "Loss: 1.8567888736724854| Acc: 35.23809523809524\n",
      "Epoch: 381 \n",
      "-----------\n",
      "Loss: 1.854223608970642| Acc: 34.285714285714285\n",
      "Epoch: 382 \n",
      "-----------\n",
      "Loss: 1.8536654710769653| Acc: 35.23809523809524\n",
      "Epoch: 383 \n",
      "-----------\n",
      "Loss: 1.8542124032974243| Acc: 34.285714285714285\n",
      "Epoch: 384 \n",
      "-----------\n",
      "Loss: 1.854629397392273| Acc: 34.285714285714285\n",
      "Epoch: 385 \n",
      "-----------\n",
      "Loss: 1.8551090955734253| Acc: 34.285714285714285\n",
      "Epoch: 386 \n",
      "-----------\n",
      "Loss: 1.8548120260238647| Acc: 34.285714285714285\n",
      "Epoch: 387 \n",
      "-----------\n",
      "Loss: 1.854910135269165| Acc: 34.285714285714285\n",
      "Epoch: 388 \n",
      "-----------\n",
      "Loss: 1.8548002243041992| Acc: 33.33333333333333\n",
      "Epoch: 389 \n",
      "-----------\n",
      "Loss: 1.8548614978790283| Acc: 33.33333333333333\n",
      "Epoch: 390 \n",
      "-----------\n",
      "Loss: 1.8550790548324585| Acc: 33.33333333333333\n",
      "Epoch: 391 \n",
      "-----------\n",
      "Loss: 1.8551671504974365| Acc: 33.33333333333333\n",
      "Epoch: 392 \n",
      "-----------\n",
      "Loss: 1.8552783727645874| Acc: 33.33333333333333\n",
      "Epoch: 393 \n",
      "-----------\n",
      "Loss: 1.855502724647522| Acc: 33.33333333333333\n",
      "Epoch: 394 \n",
      "-----------\n",
      "Loss: 1.855283260345459| Acc: 33.33333333333333\n",
      "Epoch: 395 \n",
      "-----------\n",
      "Loss: 1.8552597761154175| Acc: 32.38095238095238\n",
      "Epoch: 396 \n",
      "-----------\n",
      "Loss: 1.855255126953125| Acc: 33.33333333333333\n",
      "Epoch: 397 \n",
      "-----------\n",
      "Loss: 1.8553565740585327| Acc: 32.38095238095238\n",
      "Epoch: 398 \n",
      "-----------\n",
      "Loss: 1.8576781749725342| Acc: 33.33333333333333\n",
      "Epoch: 399 \n",
      "-----------\n",
      "Loss: 1.8549150228500366| Acc: 33.33333333333333\n",
      "Epoch: 400 \n",
      "-----------\n",
      "Loss: 1.854902982711792| Acc: 33.33333333333333\n",
      "Epoch: 401 \n",
      "-----------\n",
      "Loss: 1.855256199836731| Acc: 33.33333333333333\n",
      "Epoch: 402 \n",
      "-----------\n",
      "Loss: 1.8548848628997803| Acc: 33.33333333333333\n",
      "Epoch: 403 \n",
      "-----------\n",
      "Loss: 1.855019211769104| Acc: 32.38095238095238\n",
      "Epoch: 404 \n",
      "-----------\n",
      "Loss: 1.8547208309173584| Acc: 32.38095238095238\n",
      "Epoch: 405 \n",
      "-----------\n",
      "Loss: 1.8545113801956177| Acc: 32.38095238095238\n",
      "Epoch: 406 \n",
      "-----------\n",
      "Loss: 1.8545401096343994| Acc: 32.38095238095238\n",
      "Epoch: 407 \n",
      "-----------\n",
      "Loss: 1.85472571849823| Acc: 33.33333333333333\n",
      "Epoch: 408 \n",
      "-----------\n",
      "Loss: 1.8644282817840576| Acc: 32.38095238095238\n",
      "Epoch: 409 \n",
      "-----------\n",
      "Loss: 1.853271245956421| Acc: 33.33333333333333\n",
      "Epoch: 410 \n",
      "-----------\n",
      "Loss: 1.865516185760498| Acc: 32.38095238095238\n",
      "Epoch: 411 \n",
      "-----------\n",
      "Loss: 1.853645920753479| Acc: 32.38095238095238\n",
      "Epoch: 412 \n",
      "-----------\n",
      "Loss: 1.852938175201416| Acc: 33.33333333333333\n",
      "Epoch: 413 \n",
      "-----------\n",
      "Loss: 1.85551917552948| Acc: 32.38095238095238\n",
      "Epoch: 414 \n",
      "-----------\n",
      "Loss: 1.8533374071121216| Acc: 33.33333333333333\n",
      "Epoch: 415 \n",
      "-----------\n",
      "Loss: 1.8548299074172974| Acc: 33.33333333333333\n",
      "Epoch: 416 \n",
      "-----------\n",
      "Loss: 1.854984998703003| Acc: 32.38095238095238\n",
      "Epoch: 417 \n",
      "-----------\n",
      "Loss: 1.8534235954284668| Acc: 33.33333333333333\n",
      "Epoch: 418 \n",
      "-----------\n",
      "Loss: 1.8534133434295654| Acc: 33.33333333333333\n",
      "Epoch: 419 \n",
      "-----------\n",
      "Loss: 1.852203607559204| Acc: 33.33333333333333\n",
      "Epoch: 420 \n",
      "-----------\n",
      "Loss: 1.8603370189666748| Acc: 32.38095238095238\n",
      "Epoch: 421 \n",
      "-----------\n",
      "Loss: 2.0320065021514893| Acc: 24.761904761904763\n",
      "Epoch: 422 \n",
      "-----------\n",
      "Loss: 1.9083161354064941| Acc: 39.04761904761905\n",
      "Epoch: 423 \n",
      "-----------\n",
      "Loss: 1.903627634048462| Acc: 40.0\n",
      "Epoch: 424 \n",
      "-----------\n",
      "Loss: 1.8973946571350098| Acc: 39.04761904761905\n",
      "Epoch: 425 \n",
      "-----------\n",
      "Loss: 1.8963960409164429| Acc: 40.95238095238095\n",
      "Epoch: 426 \n",
      "-----------\n",
      "Loss: 1.896694540977478| Acc: 40.0\n",
      "Epoch: 427 \n",
      "-----------\n",
      "Loss: 1.8971346616744995| Acc: 38.095238095238095\n",
      "Epoch: 428 \n",
      "-----------\n",
      "Loss: 1.897262692451477| Acc: 38.095238095238095\n",
      "Epoch: 429 \n",
      "-----------\n",
      "Loss: 1.8961137533187866| Acc: 39.04761904761905\n",
      "Epoch: 430 \n",
      "-----------\n",
      "Loss: 1.8961063623428345| Acc: 40.0\n",
      "Epoch: 431 \n",
      "-----------\n",
      "Loss: 1.8883386850357056| Acc: 39.04761904761905\n",
      "Epoch: 432 \n",
      "-----------\n",
      "Loss: 1.8858296871185303| Acc: 40.95238095238095\n",
      "Epoch: 433 \n",
      "-----------\n",
      "Loss: 1.8845176696777344| Acc: 40.95238095238095\n",
      "Epoch: 434 \n",
      "-----------\n",
      "Loss: 1.929731845855713| Acc: 39.04761904761905\n",
      "Epoch: 435 \n",
      "-----------\n",
      "Loss: 1.893264889717102| Acc: 41.904761904761905\n",
      "Epoch: 436 \n",
      "-----------\n",
      "Loss: 1.8844975233078003| Acc: 43.80952380952381\n",
      "Epoch: 437 \n",
      "-----------\n",
      "Loss: 1.8842917680740356| Acc: 43.80952380952381\n",
      "Epoch: 438 \n",
      "-----------\n",
      "Loss: 1.8946309089660645| Acc: 39.04761904761905\n",
      "Epoch: 439 \n",
      "-----------\n",
      "Loss: 1.8863744735717773| Acc: 39.04761904761905\n",
      "Epoch: 440 \n",
      "-----------\n",
      "Loss: 1.885892391204834| Acc: 41.904761904761905\n",
      "Epoch: 441 \n",
      "-----------\n",
      "Loss: 1.8867160081863403| Acc: 42.857142857142854\n",
      "Epoch: 442 \n",
      "-----------\n",
      "Loss: 1.8858524560928345| Acc: 40.0\n",
      "Epoch: 443 \n",
      "-----------\n",
      "Loss: 1.8862218856811523| Acc: 39.04761904761905\n",
      "Epoch: 444 \n",
      "-----------\n",
      "Loss: 1.8858656883239746| Acc: 41.904761904761905\n",
      "Epoch: 445 \n",
      "-----------\n",
      "Loss: 1.885504126548767| Acc: 42.857142857142854\n",
      "Epoch: 446 \n",
      "-----------\n",
      "Loss: 1.8848341703414917| Acc: 40.95238095238095\n",
      "Epoch: 447 \n",
      "-----------\n",
      "Loss: 1.8855153322219849| Acc: 40.95238095238095\n",
      "Epoch: 448 \n",
      "-----------\n",
      "Loss: 1.884351134300232| Acc: 41.904761904761905\n",
      "Epoch: 449 \n",
      "-----------\n",
      "Loss: 1.8852988481521606| Acc: 42.857142857142854\n",
      "Epoch: 450 \n",
      "-----------\n",
      "Loss: 1.8850129842758179| Acc: 40.0\n",
      "Epoch: 451 \n",
      "-----------\n",
      "Loss: 1.8852533102035522| Acc: 41.904761904761905\n",
      "Epoch: 452 \n",
      "-----------\n",
      "Loss: 1.883895993232727| Acc: 40.95238095238095\n",
      "Epoch: 453 \n",
      "-----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.885486364364624| Acc: 41.904761904761905\n",
      "Epoch: 454 \n",
      "-----------\n",
      "Loss: 1.884893536567688| Acc: 40.95238095238095\n",
      "Epoch: 455 \n",
      "-----------\n",
      "Loss: 1.9246399402618408| Acc: 37.142857142857146\n",
      "Epoch: 456 \n",
      "-----------\n",
      "Loss: 1.8852657079696655| Acc: 40.95238095238095\n",
      "Epoch: 457 \n",
      "-----------\n",
      "Loss: 1.8839225769042969| Acc: 42.857142857142854\n",
      "Epoch: 458 \n",
      "-----------\n",
      "Loss: 1.8829610347747803| Acc: 41.904761904761905\n",
      "Epoch: 459 \n",
      "-----------\n",
      "Loss: 1.8826664686203003| Acc: 41.904761904761905\n",
      "Epoch: 460 \n",
      "-----------\n",
      "Loss: 1.8838987350463867| Acc: 40.0\n",
      "Epoch: 461 \n",
      "-----------\n",
      "Loss: 1.8841407299041748| Acc: 40.95238095238095\n",
      "Epoch: 462 \n",
      "-----------\n",
      "Loss: 1.8838634490966797| Acc: 40.0\n",
      "Epoch: 463 \n",
      "-----------\n",
      "Loss: 1.8833287954330444| Acc: 40.0\n",
      "Epoch: 464 \n",
      "-----------\n",
      "Loss: 1.8833354711532593| Acc: 40.0\n",
      "Epoch: 465 \n",
      "-----------\n",
      "Loss: 1.8831032514572144| Acc: 40.0\n",
      "Epoch: 466 \n",
      "-----------\n",
      "Loss: 1.8830033540725708| Acc: 40.0\n",
      "Epoch: 467 \n",
      "-----------\n",
      "Loss: 1.8829034566879272| Acc: 40.0\n",
      "Epoch: 468 \n",
      "-----------\n",
      "Loss: 1.883398175239563| Acc: 40.0\n",
      "Epoch: 469 \n",
      "-----------\n",
      "Loss: 1.8831202983856201| Acc: 40.0\n",
      "Epoch: 470 \n",
      "-----------\n",
      "Loss: 1.8833129405975342| Acc: 40.0\n",
      "Epoch: 471 \n",
      "-----------\n",
      "Loss: 1.8839236497879028| Acc: 40.95238095238095\n",
      "Epoch: 472 \n",
      "-----------\n",
      "Loss: 1.8836263418197632| Acc: 40.0\n",
      "Epoch: 473 \n",
      "-----------\n",
      "Loss: 1.8837586641311646| Acc: 40.0\n",
      "Epoch: 474 \n",
      "-----------\n",
      "Loss: 1.8833975791931152| Acc: 40.0\n",
      "Epoch: 475 \n",
      "-----------\n",
      "Loss: 1.8842381238937378| Acc: 40.0\n",
      "Epoch: 476 \n",
      "-----------\n",
      "Loss: 1.883624792098999| Acc: 40.0\n",
      "Epoch: 477 \n",
      "-----------\n",
      "Loss: 1.883540391921997| Acc: 40.0\n",
      "Epoch: 478 \n",
      "-----------\n",
      "Loss: 1.88352370262146| Acc: 40.0\n",
      "Epoch: 479 \n",
      "-----------\n",
      "Loss: 1.883423089981079| Acc: 40.0\n",
      "Epoch: 480 \n",
      "-----------\n",
      "Loss: 1.8838355541229248| Acc: 40.0\n",
      "Epoch: 481 \n",
      "-----------\n",
      "Loss: 1.883542776107788| Acc: 40.0\n",
      "Epoch: 482 \n",
      "-----------\n",
      "Loss: 1.883199691772461| Acc: 40.0\n",
      "Epoch: 483 \n",
      "-----------\n",
      "Loss: 1.883160948753357| Acc: 40.0\n",
      "Epoch: 484 \n",
      "-----------\n",
      "Loss: 1.8835135698318481| Acc: 40.0\n",
      "Epoch: 485 \n",
      "-----------\n",
      "Loss: 1.8834035396575928| Acc: 40.0\n",
      "Epoch: 486 \n",
      "-----------\n",
      "Loss: 1.8834558725357056| Acc: 40.0\n",
      "Epoch: 487 \n",
      "-----------\n",
      "Loss: 1.8845643997192383| Acc: 40.0\n",
      "Epoch: 488 \n",
      "-----------\n",
      "Loss: 1.9297871589660645| Acc: 37.142857142857146\n",
      "Epoch: 489 \n",
      "-----------\n",
      "Loss: 1.9087207317352295| Acc: 38.095238095238095\n",
      "Epoch: 490 \n",
      "-----------\n",
      "Loss: 1.8971936702728271| Acc: 39.04761904761905\n",
      "Epoch: 491 \n",
      "-----------\n",
      "Loss: 1.8959647417068481| Acc: 40.0\n",
      "Epoch: 492 \n",
      "-----------\n",
      "Loss: 1.8847119808197021| Acc: 39.04761904761905\n",
      "Epoch: 493 \n",
      "-----------\n",
      "Loss: 1.896795392036438| Acc: 38.095238095238095\n",
      "Epoch: 494 \n",
      "-----------\n",
      "Loss: 1.894753336906433| Acc: 39.04761904761905\n",
      "Epoch: 495 \n",
      "-----------\n",
      "Loss: 1.8830617666244507| Acc: 40.0\n",
      "Epoch: 496 \n",
      "-----------\n",
      "Loss: 1.883129596710205| Acc: 40.95238095238095\n",
      "Epoch: 497 \n",
      "-----------\n",
      "Loss: 1.8834558725357056| Acc: 40.95238095238095\n",
      "Epoch: 498 \n",
      "-----------\n",
      "Loss: 1.8829666376113892| Acc: 41.904761904761905\n",
      "Epoch: 499 \n",
      "-----------\n",
      "Loss: 1.8826581239700317| Acc: 41.904761904761905\n"
     ]
    }
   ],
   "source": [
    "# Set the number of epochs\n",
    "epochs = 500\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch} \\n-----------\")\n",
    "    ### Training\n",
    "    train_step(model=model_0,\n",
    "                   data_loader=train_data_loader,\n",
    "                   loss_fn=loss_fn,\n",
    "                   optimizer=optimizer,\n",
    "                   accuracy_fn=accuracy_fn,\n",
    "                   device=device)\n",
    "    \n",
    "      \n",
    "\n",
    "#       ###testing\n",
    "#       test_step(model=model_0,\n",
    "#                    data_loader=test_data_loader,\n",
    "#                    loss_fn=loss_fn,\n",
    "#                    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0791d23d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1.0.weight',\n",
       "              tensor([[[[ 0.1262, -0.2496, -0.0866],\n",
       "                        [ 0.0948,  0.1738, -0.2108],\n",
       "                        [-0.0852, -0.0400, -0.2270]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0211, -0.2082, -0.0007],\n",
       "                        [-0.3153,  0.1820, -0.2415],\n",
       "                        [ 0.2751,  0.2665, -0.0075]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2520, -0.2293,  0.1595],\n",
       "                        [ 0.1830, -0.1351, -0.2217],\n",
       "                        [-0.2916,  0.3143, -0.1490]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1632, -0.2727, -0.0650],\n",
       "                        [ 0.2939,  0.2563, -0.2404],\n",
       "                        [ 0.2418,  0.0488, -0.2206]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1020, -0.1028, -0.0249],\n",
       "                        [-0.1314,  0.0839, -0.0338],\n",
       "                        [ 0.0635,  0.0525, -0.3277]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2788,  0.0119, -0.2865],\n",
       "                        [ 0.1880, -0.3212,  0.0811],\n",
       "                        [-0.2435, -0.1931, -0.2530]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2049, -0.0515, -0.2310],\n",
       "                        [ 0.1790,  0.2966,  0.2196],\n",
       "                        [ 0.3027, -0.2006, -0.0130]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0812, -0.0228, -0.1301],\n",
       "                        [ 0.2057, -0.2018, -0.3063],\n",
       "                        [ 0.3383,  0.3160, -0.1551]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1885, -0.0080,  0.2922],\n",
       "                        [ 0.2334, -0.2865,  0.0608],\n",
       "                        [-0.1342,  0.2374,  0.1519]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1781,  0.1629, -0.2825],\n",
       "                        [ 0.2398, -0.1821,  0.2787],\n",
       "                        [ 0.0202,  0.2334,  0.0218]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2077, -0.0297,  0.2955],\n",
       "                        [ 0.0684,  0.2702, -0.0604],\n",
       "                        [-0.1663, -0.0794, -0.1201]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1103,  0.1205,  0.1106],\n",
       "                        [-0.0943,  0.0135,  0.2015],\n",
       "                        [-0.3021, -0.0100,  0.0155]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1505,  0.1430,  0.2132],\n",
       "                        [-0.2463, -0.1130,  0.0824],\n",
       "                        [ 0.1080, -0.1874,  0.0150]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3114,  0.1459, -0.2261],\n",
       "                        [ 0.2436,  0.3219,  0.1158],\n",
       "                        [-0.0195,  0.0562,  0.1146]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1788,  0.0557,  0.1238],\n",
       "                        [ 0.2673, -0.2791,  0.2736],\n",
       "                        [ 0.0805,  0.2304,  0.0143]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1298, -0.0126, -0.1923],\n",
       "                        [-0.2670,  0.1385,  0.1932],\n",
       "                        [ 0.2001,  0.1290,  0.0749]]]], device='cuda:0')),\n",
       "             ('conv1.0.bias',\n",
       "              tensor([ 0.0572, -0.2212,  0.0716,  0.1011,  0.0796,  0.2771,  0.1365,  0.0720,\n",
       "                      -0.2289,  0.0701, -0.0773, -0.2998, -0.1591, -0.2594, -0.1523, -0.2096],\n",
       "                     device='cuda:0')),\n",
       "             ('conv2.0.weight',\n",
       "              tensor([[[[-2.3312e-02, -4.7571e-02, -1.7528e-02],\n",
       "                        [-1.2227e-02,  6.9827e-02,  5.1459e-02],\n",
       "                        [ 2.4531e-02, -5.6596e-02, -1.6998e-02]],\n",
       "              \n",
       "                       [[ 3.0407e-02, -2.5548e-02,  5.4114e-02],\n",
       "                        [ 3.0938e-02, -6.2126e-02,  6.1743e-02],\n",
       "                        [-2.0852e-02, -8.5609e-03, -2.6886e-02]],\n",
       "              \n",
       "                       [[ 3.6935e-03,  6.9317e-02, -4.2467e-02],\n",
       "                        [ 9.0024e-03,  4.6555e-02, -3.8494e-02],\n",
       "                        [-8.1514e-03,  6.9461e-02,  2.7934e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.2544e-02, -5.9399e-02,  5.3681e-02],\n",
       "                        [ 2.1437e-02,  5.3769e-02, -1.7710e-03],\n",
       "                        [-4.1439e-02,  3.6053e-02,  4.5571e-02]],\n",
       "              \n",
       "                       [[ 7.9335e-04, -1.0734e-02,  5.4388e-02],\n",
       "                        [ 6.8454e-02,  1.2382e-02,  6.4270e-02],\n",
       "                        [-7.6816e-03, -9.8769e-03,  7.6547e-02]],\n",
       "              \n",
       "                       [[-1.8868e-02, -2.9869e-02,  6.4241e-03],\n",
       "                        [ 1.1062e-02,  4.3639e-02,  2.5788e-02],\n",
       "                        [ 1.5741e-02,  6.1340e-02,  9.4696e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.0502e-02, -7.1353e-02, -6.8839e-02],\n",
       "                        [-5.5401e-02,  1.4623e-03, -6.8983e-02],\n",
       "                        [-3.8679e-02,  4.9638e-02, -7.2012e-02]],\n",
       "              \n",
       "                       [[ 7.3606e-02,  4.9449e-02, -2.3728e-02],\n",
       "                        [ 1.6002e-02, -4.6908e-02,  5.8114e-02],\n",
       "                        [-4.6853e-02, -7.2728e-02, -1.8277e-02]],\n",
       "              \n",
       "                       [[ 2.5784e-02,  6.8334e-02, -5.5782e-02],\n",
       "                        [-2.1373e-02,  7.8159e-02,  8.2512e-02],\n",
       "                        [ 3.3676e-02, -5.0380e-02, -4.0823e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.3490e-02,  7.9466e-02,  2.6222e-03],\n",
       "                        [ 2.8567e-02, -9.2539e-03, -5.3003e-02],\n",
       "                        [-2.1480e-02, -7.9765e-02, -1.7044e-02]],\n",
       "              \n",
       "                       [[ 3.3240e-02, -2.0601e-02, -1.6718e-02],\n",
       "                        [-2.9489e-02,  5.1852e-02,  5.9624e-02],\n",
       "                        [ 1.2371e-02, -9.3227e-03, -4.5580e-02]],\n",
       "              \n",
       "                       [[ 7.5112e-05,  5.3891e-02,  7.0828e-02],\n",
       "                        [ 4.5287e-02, -5.9112e-02, -1.5429e-02],\n",
       "                        [ 3.5703e-03, -4.0307e-03, -6.2546e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.5729e-02,  5.2667e-02, -5.9551e-02],\n",
       "                        [ 3.7550e-02,  7.3453e-02, -7.5143e-02],\n",
       "                        [-7.5151e-02,  1.6900e-02, -2.4278e-02]],\n",
       "              \n",
       "                       [[-5.0450e-02, -2.1488e-02, -7.8123e-02],\n",
       "                        [-1.1576e-02, -1.8294e-02, -4.5004e-02],\n",
       "                        [-4.2505e-02, -3.8431e-02, -7.1584e-03]],\n",
       "              \n",
       "                       [[ 3.1392e-02, -3.4752e-02, -3.2679e-02],\n",
       "                        [-2.7293e-02, -5.9521e-02, -2.0717e-02],\n",
       "                        [ 2.1431e-02, -5.2133e-02,  8.1671e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.3112e-02, -4.7672e-02,  7.1431e-02],\n",
       "                        [ 1.8456e-02, -4.6147e-02,  4.7536e-03],\n",
       "                        [ 2.5351e-02,  1.9118e-02, -4.2708e-02]],\n",
       "              \n",
       "                       [[-3.7831e-02,  3.3542e-03, -6.7943e-03],\n",
       "                        [-7.6950e-02,  1.7345e-02, -4.4070e-03],\n",
       "                        [ 1.6303e-02, -2.9030e-02, -4.2847e-02]],\n",
       "              \n",
       "                       [[-1.3271e-02,  5.6582e-02, -6.6818e-02],\n",
       "                        [ 4.1920e-02,  6.2302e-02, -3.5764e-02],\n",
       "                        [ 7.2924e-02,  3.3102e-02, -6.7054e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-3.3238e-02,  2.3997e-03,  2.9731e-02],\n",
       "                        [-3.3388e-02, -3.0190e-02,  5.8266e-02],\n",
       "                        [-4.6666e-02, -3.0183e-02,  1.8042e-02]],\n",
       "              \n",
       "                       [[ 2.6560e-02,  4.7219e-02, -6.6146e-02],\n",
       "                        [-5.6248e-02, -4.6730e-02,  2.2170e-02],\n",
       "                        [ 2.5795e-02,  3.3638e-02,  1.3137e-03]],\n",
       "              \n",
       "                       [[-2.6200e-02, -4.2026e-02,  6.6696e-02],\n",
       "                        [ 5.2046e-02,  6.1277e-02, -5.1757e-02],\n",
       "                        [ 2.3312e-02,  6.4063e-02,  8.0631e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-5.2733e-02,  3.8959e-02, -4.0075e-02],\n",
       "                        [ 3.7423e-02, -3.0313e-02,  2.9462e-02],\n",
       "                        [ 3.2455e-02,  7.5364e-02, -3.2526e-02]],\n",
       "              \n",
       "                       [[-2.3017e-02, -1.8976e-02,  3.3270e-02],\n",
       "                        [-7.0897e-02, -6.7834e-02,  6.0847e-02],\n",
       "                        [ 1.9275e-02, -3.5568e-02,  1.2664e-02]],\n",
       "              \n",
       "                       [[-4.6741e-02,  7.9114e-02, -3.5649e-02],\n",
       "                        [ 3.3448e-02, -7.4142e-02,  3.0875e-02],\n",
       "                        [ 6.6639e-02, -1.1738e-02,  4.4742e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.8914e-02, -6.0971e-02, -7.0151e-02],\n",
       "                        [-7.6567e-02,  5.9603e-03,  2.8662e-02],\n",
       "                        [ 7.7688e-02, -1.0204e-02, -4.0294e-02]],\n",
       "              \n",
       "                       [[-5.7292e-02,  4.6681e-02, -3.0059e-02],\n",
       "                        [ 5.1024e-02, -1.3855e-02, -6.5596e-02],\n",
       "                        [-6.9553e-02,  6.0470e-02, -7.4574e-03]],\n",
       "              \n",
       "                       [[-6.1378e-02,  2.4885e-02,  1.4173e-03],\n",
       "                        [-8.1666e-02,  6.2881e-02, -3.6471e-02],\n",
       "                        [ 8.1815e-02,  5.2474e-02,  3.6765e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.1041e-02,  5.5547e-02,  1.2184e-02],\n",
       "                        [-3.9705e-02,  7.4703e-02,  2.0848e-02],\n",
       "                        [ 1.2371e-02, -6.9352e-03,  2.8624e-02]],\n",
       "              \n",
       "                       [[-7.6820e-02, -5.7662e-02, -6.9089e-02],\n",
       "                        [ 3.7292e-02,  6.0754e-03,  5.0118e-02],\n",
       "                        [ 3.8145e-02,  9.6589e-04,  7.5149e-02]],\n",
       "              \n",
       "                       [[ 8.2887e-02,  1.7865e-02,  4.1535e-02],\n",
       "                        [ 6.3527e-03,  4.4398e-03,  2.3681e-02],\n",
       "                        [-6.7261e-02,  3.0969e-02, -7.4517e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.9244e-02,  7.3389e-02,  7.8979e-02],\n",
       "                        [ 1.3468e-02,  5.2371e-03,  4.0143e-02],\n",
       "                        [ 5.6826e-02,  2.1346e-02,  3.0712e-02]],\n",
       "              \n",
       "                       [[-6.8601e-02,  5.3173e-02, -6.5872e-02],\n",
       "                        [ 4.8256e-02, -1.6548e-02,  4.0680e-02],\n",
       "                        [ 6.4229e-02, -6.7303e-03, -1.8630e-02]],\n",
       "              \n",
       "                       [[ 8.4792e-02, -1.5098e-02,  5.4576e-02],\n",
       "                        [ 3.8022e-02,  3.2167e-02,  4.9491e-02],\n",
       "                        [-4.8437e-02, -3.3780e-02, -5.6267e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 7.4024e-02, -3.2588e-02, -1.7085e-02],\n",
       "                        [ 2.0511e-02,  3.5372e-05, -7.8916e-02],\n",
       "                        [ 6.9962e-02, -5.9115e-02,  2.6015e-02]],\n",
       "              \n",
       "                       [[ 4.9953e-02, -5.1527e-02,  7.8139e-02],\n",
       "                        [ 3.9353e-02,  7.4113e-02, -5.9020e-02],\n",
       "                        [-3.1407e-02,  6.8868e-02,  3.4699e-02]],\n",
       "              \n",
       "                       [[-7.1916e-02, -2.9169e-02,  2.5012e-02],\n",
       "                        [ 7.7572e-02, -4.1583e-02, -1.1788e-02],\n",
       "                        [-6.5295e-02,  6.7669e-02,  6.3351e-02]]]], device='cuda:0')),\n",
       "             ('conv2.0.bias',\n",
       "              tensor([ 0.0681,  0.0686, -0.0023, -0.0591,  0.0067, -0.0782, -0.0305,  0.0312,\n",
       "                       0.0590, -0.0482,  0.0591,  0.0317, -0.0271, -0.0529, -0.0029,  0.0625,\n",
       "                       0.0810,  0.0017,  0.0561,  0.0546, -0.0577, -0.0064,  0.0239, -0.0301,\n",
       "                       0.0136,  0.0130,  0.0189,  0.0737,  0.0247, -0.0030,  0.0797, -0.0326],\n",
       "                     device='cuda:0')),\n",
       "             ('conv3.0.weight',\n",
       "              tensor([[[[ 0.0402,  0.0559,  0.0371],\n",
       "                        [ 0.0554,  0.0507, -0.0045],\n",
       "                        [-0.0079, -0.0051,  0.0122]],\n",
       "              \n",
       "                       [[-0.0457,  0.0267,  0.0154],\n",
       "                        [ 0.0309, -0.0002,  0.0259],\n",
       "                        [ 0.0367, -0.0055, -0.0511]],\n",
       "              \n",
       "                       [[-0.0209, -0.0332,  0.0569],\n",
       "                        [-0.0462, -0.0057,  0.0252],\n",
       "                        [ 0.0223,  0.0571, -0.0092]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0305,  0.0603,  0.0369],\n",
       "                        [ 0.0473,  0.0470, -0.0217],\n",
       "                        [-0.0237,  0.0327,  0.0579]],\n",
       "              \n",
       "                       [[ 0.0176,  0.0507, -0.0058],\n",
       "                        [ 0.0519, -0.0310, -0.0076],\n",
       "                        [ 0.0125, -0.0334, -0.0528]],\n",
       "              \n",
       "                       [[-0.0471,  0.0245, -0.0039],\n",
       "                        [ 0.0143, -0.0545,  0.0240],\n",
       "                        [-0.0315,  0.0335, -0.0013]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0296,  0.0137, -0.0105],\n",
       "                        [ 0.0064,  0.0448,  0.0229],\n",
       "                        [ 0.0062, -0.0331, -0.0180]],\n",
       "              \n",
       "                       [[ 0.0580, -0.0343,  0.0063],\n",
       "                        [-0.0462,  0.0143,  0.0337],\n",
       "                        [-0.0054, -0.0098,  0.0523]],\n",
       "              \n",
       "                       [[-0.0443, -0.0187,  0.0509],\n",
       "                        [-0.0459,  0.0172,  0.0030],\n",
       "                        [ 0.0317, -0.0393,  0.0170]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0341, -0.0092, -0.0316],\n",
       "                        [ 0.0551,  0.0563, -0.0281],\n",
       "                        [-0.0518,  0.0243,  0.0299]],\n",
       "              \n",
       "                       [[-0.0119, -0.0377,  0.0557],\n",
       "                        [-0.0402,  0.0483, -0.0028],\n",
       "                        [ 0.0051, -0.0370,  0.0464]],\n",
       "              \n",
       "                       [[-0.0472, -0.0226,  0.0488],\n",
       "                        [-0.0467, -0.0558,  0.0171],\n",
       "                        [-0.0055, -0.0094, -0.0336]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0387, -0.0270,  0.0016],\n",
       "                        [ 0.0354,  0.0226,  0.0365],\n",
       "                        [ 0.0556, -0.0083,  0.0449]],\n",
       "              \n",
       "                       [[ 0.0115,  0.0311, -0.0269],\n",
       "                        [ 0.0372, -0.0436, -0.0409],\n",
       "                        [-0.0234, -0.0466, -0.0538]],\n",
       "              \n",
       "                       [[ 0.0579, -0.0187, -0.0288],\n",
       "                        [-0.0141, -0.0500,  0.0190],\n",
       "                        [-0.0541,  0.0230, -0.0572]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0554,  0.0026, -0.0171],\n",
       "                        [-0.0330,  0.0306, -0.0268],\n",
       "                        [ 0.0552,  0.0450, -0.0304]],\n",
       "              \n",
       "                       [[-0.0561, -0.0571,  0.0488],\n",
       "                        [ 0.0559, -0.0557,  0.0240],\n",
       "                        [ 0.0323,  0.0067,  0.0143]],\n",
       "              \n",
       "                       [[-0.0315,  0.0033, -0.0165],\n",
       "                        [-0.0057,  0.0332,  0.0596],\n",
       "                        [-0.0331, -0.0103,  0.0140]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0284, -0.0397, -0.0219],\n",
       "                        [ 0.0215, -0.0481, -0.0590],\n",
       "                        [ 0.0254, -0.0323,  0.0068]],\n",
       "              \n",
       "                       [[ 0.0132, -0.0496,  0.0003],\n",
       "                        [-0.0542, -0.0227, -0.0526],\n",
       "                        [-0.0146,  0.0476, -0.0296]],\n",
       "              \n",
       "                       [[ 0.0415, -0.0489, -0.0181],\n",
       "                        [-0.0221, -0.0403, -0.0583],\n",
       "                        [ 0.0480,  0.0502, -0.0295]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0503,  0.0307, -0.0502],\n",
       "                        [ 0.0428, -0.0561,  0.0258],\n",
       "                        [ 0.0352, -0.0104,  0.0541]],\n",
       "              \n",
       "                       [[-0.0443,  0.0538, -0.0203],\n",
       "                        [ 0.0165, -0.0266, -0.0072],\n",
       "                        [-0.0181, -0.0082,  0.0488]],\n",
       "              \n",
       "                       [[-0.0195, -0.0051,  0.0210],\n",
       "                        [-0.0369, -0.0384, -0.0579],\n",
       "                        [ 0.0390, -0.0236,  0.0518]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0398, -0.0479,  0.0396],\n",
       "                        [ 0.0223, -0.0127, -0.0381],\n",
       "                        [-0.0214, -0.0474, -0.0543]],\n",
       "              \n",
       "                       [[ 0.0517,  0.0312, -0.0521],\n",
       "                        [-0.0562,  0.0123, -0.0323],\n",
       "                        [-0.0450, -0.0574, -0.0313]],\n",
       "              \n",
       "                       [[ 0.0010, -0.0446,  0.0303],\n",
       "                        [ 0.0399, -0.0113,  0.0250],\n",
       "                        [-0.0579, -0.0564,  0.0389]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0268, -0.0456,  0.0579],\n",
       "                        [-0.0266,  0.0269,  0.0248],\n",
       "                        [-0.0587, -0.0350,  0.0041]],\n",
       "              \n",
       "                       [[-0.0498,  0.0444, -0.0196],\n",
       "                        [ 0.0257, -0.0329, -0.0516],\n",
       "                        [ 0.0480, -0.0559,  0.0462]],\n",
       "              \n",
       "                       [[ 0.0549, -0.0277, -0.0081],\n",
       "                        [-0.0058,  0.0110, -0.0570],\n",
       "                        [-0.0230, -0.0541, -0.0189]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0265,  0.0048,  0.0052],\n",
       "                        [-0.0234,  0.0389,  0.0517],\n",
       "                        [-0.0333,  0.0459, -0.0405]],\n",
       "              \n",
       "                       [[ 0.0271, -0.0190, -0.0298],\n",
       "                        [-0.0270, -0.0246,  0.0227],\n",
       "                        [ 0.0527, -0.0239, -0.0069]],\n",
       "              \n",
       "                       [[ 0.0149,  0.0187,  0.0203],\n",
       "                        [-0.0005,  0.0595,  0.0557],\n",
       "                        [ 0.0441,  0.0014,  0.0561]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0509,  0.0396,  0.0283],\n",
       "                        [-0.0177,  0.0241,  0.0509],\n",
       "                        [ 0.0153, -0.0050, -0.0020]],\n",
       "              \n",
       "                       [[-0.0176,  0.0573, -0.0546],\n",
       "                        [ 0.0062,  0.0402, -0.0354],\n",
       "                        [-0.0131,  0.0326,  0.0486]],\n",
       "              \n",
       "                       [[-0.0228, -0.0067,  0.0431],\n",
       "                        [ 0.0121, -0.0232,  0.0039],\n",
       "                        [-0.0547, -0.0055,  0.0175]]]], device='cuda:0')),\n",
       "             ('conv3.0.bias',\n",
       "              tensor([ 0.0008,  0.0339,  0.0267,  0.0057, -0.0093,  0.0149, -0.0011,  0.0464,\n",
       "                      -0.0035,  0.0527, -0.0063, -0.0421, -0.0010, -0.0233,  0.0128,  0.0004,\n",
       "                       0.0415,  0.0291,  0.0536,  0.0136,  0.0341, -0.0277, -0.0235,  0.0566,\n",
       "                      -0.0245,  0.0518, -0.0384,  0.0266,  0.0535,  0.0044, -0.0414,  0.0460,\n",
       "                      -0.0117,  0.0308,  0.0350, -0.0029, -0.0217,  0.0071,  0.0272,  0.0272,\n",
       "                      -0.0323,  0.0040, -0.0175, -0.0498,  0.0296, -0.0014, -0.0539,  0.0458,\n",
       "                      -0.0338, -0.0575, -0.0196, -0.0061,  0.0375,  0.0342, -0.0015, -0.0148,\n",
       "                      -0.0098, -0.0297, -0.0393,  0.0493,  0.0241,  0.0090,  0.0236,  0.0526],\n",
       "                     device='cuda:0')),\n",
       "             ('conv4.0.weight',\n",
       "              tensor([[[[ 2.5689e-02,  2.3269e-02,  3.5009e-02],\n",
       "                        [ 2.9758e-02,  3.2505e-02,  7.4809e-03],\n",
       "                        [-1.6373e-02, -1.8257e-02,  4.3677e-03]],\n",
       "              \n",
       "                       [[ 1.4356e-02,  3.9927e-02,  3.8961e-02],\n",
       "                        [-2.6442e-02, -7.2153e-04, -8.4734e-05],\n",
       "                        [-2.6317e-02, -3.5710e-02,  1.7511e-03]],\n",
       "              \n",
       "                       [[ 1.0592e-02,  1.9306e-03, -2.3347e-02],\n",
       "                        [-2.5676e-02,  9.4564e-03,  8.8491e-03],\n",
       "                        [-2.4528e-02,  2.7408e-02,  7.7537e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.9977e-02,  1.7542e-02,  2.7735e-02],\n",
       "                        [-6.5693e-03,  3.0023e-02,  2.9793e-02],\n",
       "                        [-3.9802e-02,  8.2648e-04,  3.7244e-02]],\n",
       "              \n",
       "                       [[-1.6734e-02, -2.2382e-02, -2.5819e-02],\n",
       "                        [-3.7070e-02, -3.9288e-02,  1.2274e-03],\n",
       "                        [ 1.7594e-03, -2.2561e-02,  3.5825e-02]],\n",
       "              \n",
       "                       [[-4.0889e-02, -3.3174e-02, -2.0074e-02],\n",
       "                        [ 2.4307e-02, -4.6206e-03,  8.7841e-03],\n",
       "                        [-3.3131e-02, -9.9480e-03, -1.4582e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.5894e-02, -3.7950e-02, -3.1416e-02],\n",
       "                        [-1.0023e-02,  1.3860e-02, -3.3804e-03],\n",
       "                        [-3.7287e-02,  2.8953e-02, -3.0955e-02]],\n",
       "              \n",
       "                       [[ 7.2868e-03, -1.6866e-02,  2.8294e-02],\n",
       "                        [ 4.1218e-03, -3.1154e-02,  2.6204e-02],\n",
       "                        [ 3.2647e-03, -2.9980e-02, -3.5527e-02]],\n",
       "              \n",
       "                       [[-1.0619e-02, -2.2019e-02, -1.3478e-02],\n",
       "                        [ 1.4744e-02,  2.9564e-02,  4.2700e-02],\n",
       "                        [-2.4009e-02,  2.5458e-02, -2.8794e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.4308e-03, -2.4540e-02,  1.6617e-02],\n",
       "                        [ 6.1015e-03,  2.8306e-02,  1.4719e-04],\n",
       "                        [-3.4935e-02,  1.9212e-02, -2.8907e-02]],\n",
       "              \n",
       "                       [[-3.4470e-02, -2.2571e-02, -2.3344e-02],\n",
       "                        [-1.1146e-02, -3.2305e-02,  2.8155e-02],\n",
       "                        [-1.7797e-02,  1.7274e-02,  1.5187e-02]],\n",
       "              \n",
       "                       [[ 1.1712e-02, -1.5783e-02,  2.6262e-02],\n",
       "                        [-1.5875e-02,  3.0541e-02,  2.2294e-02],\n",
       "                        [ 3.7820e-02, -4.2982e-03,  4.6386e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.2315e-02,  1.8453e-02,  2.6567e-02],\n",
       "                        [-1.4630e-02, -3.9206e-02,  4.1390e-02],\n",
       "                        [ 2.6336e-02,  4.2683e-02,  9.1749e-03]],\n",
       "              \n",
       "                       [[-2.6106e-02,  3.0793e-02,  4.8731e-03],\n",
       "                        [ 3.7164e-02,  1.7333e-02,  1.2487e-02],\n",
       "                        [ 1.7320e-03, -2.2470e-02,  3.9898e-02]],\n",
       "              \n",
       "                       [[ 2.4699e-02,  1.8290e-02,  3.4445e-03],\n",
       "                        [-1.1392e-02,  3.7904e-02,  3.2710e-03],\n",
       "                        [ 4.0538e-02,  2.6499e-02,  1.1742e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.7368e-03, -1.9141e-02, -1.0397e-02],\n",
       "                        [-3.5815e-02, -3.9866e-02, -1.3193e-02],\n",
       "                        [-2.7911e-02, -2.4162e-02,  3.8995e-02]],\n",
       "              \n",
       "                       [[-1.4545e-02,  3.7194e-02,  3.6436e-02],\n",
       "                        [ 7.9557e-03, -2.6574e-02,  1.6427e-02],\n",
       "                        [-2.9565e-02,  2.1037e-02,  3.5051e-02]],\n",
       "              \n",
       "                       [[-1.1556e-02,  2.8132e-02,  2.6222e-02],\n",
       "                        [-2.1354e-03, -2.7275e-02, -2.0405e-02],\n",
       "                        [ 3.1702e-02,  3.4525e-02,  3.8275e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 2.7524e-02, -4.1326e-02, -2.3177e-02],\n",
       "                        [ 3.2542e-02, -1.0385e-02, -4.0384e-02],\n",
       "                        [-1.2408e-02, -1.6564e-02,  2.1615e-02]],\n",
       "              \n",
       "                       [[ 1.3632e-03,  1.8395e-02, -2.8685e-02],\n",
       "                        [-4.0499e-02, -6.8435e-03,  1.7752e-02],\n",
       "                        [ 1.1714e-02, -2.5051e-02,  3.0007e-02]],\n",
       "              \n",
       "                       [[ 2.8656e-02, -5.1926e-03,  3.8123e-05],\n",
       "                        [-3.3366e-02, -3.7837e-02,  4.1543e-02],\n",
       "                        [-1.6917e-02, -1.8269e-02,  3.1445e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.1496e-02,  2.1277e-02, -5.5741e-03],\n",
       "                        [-7.8028e-03,  2.6081e-02, -5.5654e-04],\n",
       "                        [ 1.0239e-02,  2.5243e-02, -2.7171e-02]],\n",
       "              \n",
       "                       [[ 3.8707e-02, -5.9490e-04,  4.1418e-02],\n",
       "                        [-2.7793e-02, -3.2662e-02,  2.7635e-02],\n",
       "                        [-1.0470e-02, -2.4586e-02, -3.6526e-02]],\n",
       "              \n",
       "                       [[-2.5124e-02, -3.9081e-03, -4.2071e-03],\n",
       "                        [ 3.5872e-02, -2.7594e-02, -1.3512e-02],\n",
       "                        [-3.6271e-02, -3.8470e-03,  8.3810e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.0662e-02,  1.2117e-02,  1.9371e-02],\n",
       "                        [-1.9479e-02,  1.3675e-02,  8.8799e-04],\n",
       "                        [ 1.8472e-02, -2.6683e-02, -2.7746e-02]],\n",
       "              \n",
       "                       [[-2.7954e-03,  1.6909e-02,  1.4836e-02],\n",
       "                        [-2.5207e-02,  3.1611e-02, -3.8562e-02],\n",
       "                        [ 5.2470e-03, -1.0824e-03,  3.2882e-02]],\n",
       "              \n",
       "                       [[ 1.2885e-02, -3.8372e-02,  3.3127e-02],\n",
       "                        [ 2.6299e-02, -3.4654e-02, -6.5848e-03],\n",
       "                        [-1.6181e-02, -3.9353e-02, -8.0024e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.7313e-02, -1.3560e-02,  1.3455e-02],\n",
       "                        [ 1.5895e-02, -1.6176e-02,  2.9559e-02],\n",
       "                        [-1.2380e-02, -2.5470e-02, -3.7915e-02]],\n",
       "              \n",
       "                       [[ 1.9249e-02,  3.3744e-03,  2.9146e-02],\n",
       "                        [ 3.3598e-02, -3.6239e-03, -4.0844e-02],\n",
       "                        [ 5.7112e-04, -1.6767e-03,  3.9784e-02]],\n",
       "              \n",
       "                       [[-1.5285e-02,  2.6882e-02, -2.3162e-02],\n",
       "                        [-3.9111e-02, -2.9259e-02, -3.2602e-02],\n",
       "                        [ 3.8718e-02,  4.1565e-02, -3.4448e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4147e-02, -9.1594e-03, -3.8057e-02],\n",
       "                        [-3.1296e-02,  1.2752e-02, -3.0340e-02],\n",
       "                        [-1.4319e-02,  3.4561e-02,  3.6253e-02]],\n",
       "              \n",
       "                       [[ 3.3479e-02,  2.8160e-02,  3.6773e-02],\n",
       "                        [ 1.6554e-02,  5.8233e-03,  1.7703e-02],\n",
       "                        [ 2.4462e-03, -1.8850e-02, -2.4074e-02]],\n",
       "              \n",
       "                       [[ 2.5847e-03, -2.3605e-02,  3.7303e-02],\n",
       "                        [ 3.4160e-02, -1.7022e-02,  3.6841e-02],\n",
       "                        [ 3.5966e-02,  3.0419e-02,  7.2100e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.0103e-03,  2.8087e-02,  3.5387e-02],\n",
       "                        [ 1.2942e-02,  1.9075e-02,  2.2873e-02],\n",
       "                        [-3.7160e-02, -3.2617e-02, -1.7794e-02]],\n",
       "              \n",
       "                       [[-2.7739e-03, -1.3292e-02,  2.5076e-02],\n",
       "                        [ 2.8802e-02,  2.1138e-02,  2.0895e-02],\n",
       "                        [ 1.8828e-02,  1.9938e-02, -1.8432e-02]],\n",
       "              \n",
       "                       [[ 2.8197e-02, -7.7361e-03, -2.8912e-02],\n",
       "                        [-3.8726e-02, -2.0011e-02, -1.4948e-02],\n",
       "                        [-3.9007e-02,  3.5306e-03, -4.5278e-03]]]], device='cuda:0')),\n",
       "             ('conv4.0.bias',\n",
       "              tensor([ 0.0248,  0.0226,  0.0094, -0.0315, -0.0034,  0.0238, -0.0179,  0.0241,\n",
       "                       0.0036, -0.0279, -0.0182, -0.0115, -0.0412,  0.0283, -0.0265,  0.0283,\n",
       "                      -0.0098, -0.0363, -0.0348,  0.0111,  0.0015,  0.0367,  0.0162, -0.0056,\n",
       "                      -0.0086, -0.0275, -0.0075,  0.0321,  0.0355, -0.0074,  0.0239, -0.0157,\n",
       "                       0.0319,  0.0256, -0.0293, -0.0278, -0.0251,  0.0007, -0.0032, -0.0291,\n",
       "                      -0.0145, -0.0320,  0.0320, -0.0390,  0.0087, -0.0362,  0.0019, -0.0317,\n",
       "                       0.0229,  0.0393,  0.0052, -0.0077,  0.0168,  0.0114,  0.0059,  0.0329,\n",
       "                       0.0033, -0.0392,  0.0198,  0.0019,  0.0301,  0.0411, -0.0309,  0.0365,\n",
       "                      -0.0333, -0.0209, -0.0276, -0.0365,  0.0151, -0.0098,  0.0209, -0.0363,\n",
       "                       0.0038, -0.0295,  0.0076,  0.0135,  0.0312,  0.0211,  0.0337, -0.0415,\n",
       "                      -0.0042, -0.0315,  0.0314,  0.0231,  0.0173, -0.0114,  0.0060,  0.0009,\n",
       "                       0.0137,  0.0177, -0.0156,  0.0194, -0.0001,  0.0257, -0.0375, -0.0309,\n",
       "                      -0.0236,  0.0405, -0.0160,  0.0132,  0.0221,  0.0411,  0.0026, -0.0227,\n",
       "                       0.0062, -0.0334,  0.0166,  0.0266,  0.0278,  0.0058,  0.0041, -0.0393,\n",
       "                       0.0128, -0.0317, -0.0351,  0.0152, -0.0122, -0.0259, -0.0362,  0.0066,\n",
       "                      -0.0309,  0.0187,  0.0170,  0.0290, -0.0255, -0.0220, -0.0085, -0.0368],\n",
       "                     device='cuda:0')),\n",
       "             ('linear.weight',\n",
       "              tensor([[ 0.0063,  0.0049, -0.0070,  ..., -0.0108,  0.0109, -0.0048],\n",
       "                      [-0.0027, -0.0135,  0.0087,  ...,  0.0123, -0.0023, -0.0094],\n",
       "                      [-0.0060,  0.0157, -0.0155,  ...,  0.0124, -0.0098,  0.0025],\n",
       "                      ...,\n",
       "                      [-0.0144,  0.0050, -0.0122,  ...,  0.0044,  0.0080, -0.0133],\n",
       "                      [-0.0138,  0.0035, -0.0010,  ...,  0.0037, -0.0109, -0.0202],\n",
       "                      [-0.0239, -0.0185, -0.0024,  ...,  0.0059,  0.0052, -0.0045]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear.bias',\n",
       "              tensor([ 0.0125, -0.0120, -0.0086, -0.0197, -0.0157, -0.0153,  0.0023, -0.0174,\n",
       "                       0.0154,  0.0002], device='cuda:0'))])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a3a432ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model stored\n"
     ]
    }
   ],
   "source": [
    "torch.save(model_0.state_dict(), \"cnnnet.pth\")\n",
    "print(\"Model stored\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4960a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe025602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f795764",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
